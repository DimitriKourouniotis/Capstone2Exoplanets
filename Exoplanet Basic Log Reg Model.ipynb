{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in CSV files. The Test and Train split is an element of the Kaggle compeition source of these files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('exoTrain.csv')\n",
    "dftest = pd.read_csv('exoTest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LABEL'] = df['LABEL']-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>FLUX.1</th>\n",
       "      <th>FLUX.2</th>\n",
       "      <th>FLUX.3</th>\n",
       "      <th>FLUX.4</th>\n",
       "      <th>FLUX.5</th>\n",
       "      <th>FLUX.6</th>\n",
       "      <th>FLUX.7</th>\n",
       "      <th>FLUX.8</th>\n",
       "      <th>FLUX.9</th>\n",
       "      <th>...</th>\n",
       "      <th>FLUX.3188</th>\n",
       "      <th>FLUX.3189</th>\n",
       "      <th>FLUX.3190</th>\n",
       "      <th>FLUX.3191</th>\n",
       "      <th>FLUX.3192</th>\n",
       "      <th>FLUX.3193</th>\n",
       "      <th>FLUX.3194</th>\n",
       "      <th>FLUX.3195</th>\n",
       "      <th>FLUX.3196</th>\n",
       "      <th>FLUX.3197</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>93.85</td>\n",
       "      <td>83.81</td>\n",
       "      <td>20.10</td>\n",
       "      <td>-26.98</td>\n",
       "      <td>-39.56</td>\n",
       "      <td>-124.71</td>\n",
       "      <td>-135.18</td>\n",
       "      <td>-96.27</td>\n",
       "      <td>-79.89</td>\n",
       "      <td>...</td>\n",
       "      <td>-78.07</td>\n",
       "      <td>-102.15</td>\n",
       "      <td>-102.15</td>\n",
       "      <td>25.13</td>\n",
       "      <td>48.57</td>\n",
       "      <td>92.54</td>\n",
       "      <td>39.32</td>\n",
       "      <td>61.42</td>\n",
       "      <td>5.08</td>\n",
       "      <td>-39.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-38.88</td>\n",
       "      <td>-33.83</td>\n",
       "      <td>-58.54</td>\n",
       "      <td>-40.09</td>\n",
       "      <td>-79.31</td>\n",
       "      <td>-72.81</td>\n",
       "      <td>-86.55</td>\n",
       "      <td>-85.33</td>\n",
       "      <td>-83.97</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.28</td>\n",
       "      <td>-32.21</td>\n",
       "      <td>-32.21</td>\n",
       "      <td>-24.89</td>\n",
       "      <td>-4.86</td>\n",
       "      <td>0.76</td>\n",
       "      <td>-11.70</td>\n",
       "      <td>6.46</td>\n",
       "      <td>16.00</td>\n",
       "      <td>19.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>532.64</td>\n",
       "      <td>535.92</td>\n",
       "      <td>513.73</td>\n",
       "      <td>496.92</td>\n",
       "      <td>456.45</td>\n",
       "      <td>466.00</td>\n",
       "      <td>464.50</td>\n",
       "      <td>486.39</td>\n",
       "      <td>436.56</td>\n",
       "      <td>...</td>\n",
       "      <td>-71.69</td>\n",
       "      <td>13.31</td>\n",
       "      <td>13.31</td>\n",
       "      <td>-29.89</td>\n",
       "      <td>-20.88</td>\n",
       "      <td>5.06</td>\n",
       "      <td>-11.80</td>\n",
       "      <td>-28.91</td>\n",
       "      <td>-70.02</td>\n",
       "      <td>-96.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>326.52</td>\n",
       "      <td>347.39</td>\n",
       "      <td>302.35</td>\n",
       "      <td>298.13</td>\n",
       "      <td>317.74</td>\n",
       "      <td>312.70</td>\n",
       "      <td>322.33</td>\n",
       "      <td>311.31</td>\n",
       "      <td>312.42</td>\n",
       "      <td>...</td>\n",
       "      <td>5.71</td>\n",
       "      <td>-3.73</td>\n",
       "      <td>-3.73</td>\n",
       "      <td>30.05</td>\n",
       "      <td>20.03</td>\n",
       "      <td>-12.67</td>\n",
       "      <td>-8.77</td>\n",
       "      <td>-17.31</td>\n",
       "      <td>-17.35</td>\n",
       "      <td>13.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-1107.21</td>\n",
       "      <td>-1112.59</td>\n",
       "      <td>-1118.95</td>\n",
       "      <td>-1095.10</td>\n",
       "      <td>-1057.55</td>\n",
       "      <td>-1034.48</td>\n",
       "      <td>-998.34</td>\n",
       "      <td>-1022.71</td>\n",
       "      <td>-989.57</td>\n",
       "      <td>...</td>\n",
       "      <td>-594.37</td>\n",
       "      <td>-401.66</td>\n",
       "      <td>-401.66</td>\n",
       "      <td>-357.24</td>\n",
       "      <td>-443.76</td>\n",
       "      <td>-438.54</td>\n",
       "      <td>-399.71</td>\n",
       "      <td>-384.65</td>\n",
       "      <td>-411.79</td>\n",
       "      <td>-510.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LABEL   FLUX.1   FLUX.2   FLUX.3   FLUX.4   FLUX.5   FLUX.6  FLUX.7  \\\n",
       "0      1    93.85    83.81    20.10   -26.98   -39.56  -124.71 -135.18   \n",
       "1      1   -38.88   -33.83   -58.54   -40.09   -79.31   -72.81  -86.55   \n",
       "2      1   532.64   535.92   513.73   496.92   456.45   466.00  464.50   \n",
       "3      1   326.52   347.39   302.35   298.13   317.74   312.70  322.33   \n",
       "4      1 -1107.21 -1112.59 -1118.95 -1095.10 -1057.55 -1034.48 -998.34   \n",
       "\n",
       "    FLUX.8  FLUX.9    ...      FLUX.3188  FLUX.3189  FLUX.3190  FLUX.3191  \\\n",
       "0   -96.27  -79.89    ...         -78.07    -102.15    -102.15      25.13   \n",
       "1   -85.33  -83.97    ...          -3.28     -32.21     -32.21     -24.89   \n",
       "2   486.39  436.56    ...         -71.69      13.31      13.31     -29.89   \n",
       "3   311.31  312.42    ...           5.71      -3.73      -3.73      30.05   \n",
       "4 -1022.71 -989.57    ...        -594.37    -401.66    -401.66    -357.24   \n",
       "\n",
       "   FLUX.3192  FLUX.3193  FLUX.3194  FLUX.3195  FLUX.3196  FLUX.3197  \n",
       "0      48.57      92.54      39.32      61.42       5.08     -39.54  \n",
       "1      -4.86       0.76     -11.70       6.46      16.00      19.93  \n",
       "2     -20.88       5.06     -11.80     -28.91     -70.02     -96.67  \n",
       "3      20.03     -12.67      -8.77     -17.31     -17.35      13.98  \n",
       "4    -443.76    -438.54    -399.71    -384.65    -411.79    -510.54  \n",
       "\n",
       "[5 rows x 3198 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest['LABEL'] = dftest['LABEL']-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>FLUX.1</th>\n",
       "      <th>FLUX.2</th>\n",
       "      <th>FLUX.3</th>\n",
       "      <th>FLUX.4</th>\n",
       "      <th>FLUX.5</th>\n",
       "      <th>FLUX.6</th>\n",
       "      <th>FLUX.7</th>\n",
       "      <th>FLUX.8</th>\n",
       "      <th>FLUX.9</th>\n",
       "      <th>...</th>\n",
       "      <th>FLUX.3188</th>\n",
       "      <th>FLUX.3189</th>\n",
       "      <th>FLUX.3190</th>\n",
       "      <th>FLUX.3191</th>\n",
       "      <th>FLUX.3192</th>\n",
       "      <th>FLUX.3193</th>\n",
       "      <th>FLUX.3194</th>\n",
       "      <th>FLUX.3195</th>\n",
       "      <th>FLUX.3196</th>\n",
       "      <th>FLUX.3197</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>119.88</td>\n",
       "      <td>100.21</td>\n",
       "      <td>86.46</td>\n",
       "      <td>48.68</td>\n",
       "      <td>46.12</td>\n",
       "      <td>39.39</td>\n",
       "      <td>18.57</td>\n",
       "      <td>6.98</td>\n",
       "      <td>6.63</td>\n",
       "      <td>...</td>\n",
       "      <td>14.52</td>\n",
       "      <td>19.29</td>\n",
       "      <td>14.44</td>\n",
       "      <td>-1.62</td>\n",
       "      <td>13.33</td>\n",
       "      <td>45.50</td>\n",
       "      <td>31.93</td>\n",
       "      <td>35.78</td>\n",
       "      <td>269.43</td>\n",
       "      <td>57.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5736.59</td>\n",
       "      <td>5699.98</td>\n",
       "      <td>5717.16</td>\n",
       "      <td>5692.73</td>\n",
       "      <td>5663.83</td>\n",
       "      <td>5631.16</td>\n",
       "      <td>5626.39</td>\n",
       "      <td>5569.47</td>\n",
       "      <td>5550.44</td>\n",
       "      <td>...</td>\n",
       "      <td>-581.91</td>\n",
       "      <td>-984.09</td>\n",
       "      <td>-1230.89</td>\n",
       "      <td>-1600.45</td>\n",
       "      <td>-1824.53</td>\n",
       "      <td>-2061.17</td>\n",
       "      <td>-2265.98</td>\n",
       "      <td>-2366.19</td>\n",
       "      <td>-2294.86</td>\n",
       "      <td>-2034.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>844.48</td>\n",
       "      <td>817.49</td>\n",
       "      <td>770.07</td>\n",
       "      <td>675.01</td>\n",
       "      <td>605.52</td>\n",
       "      <td>499.45</td>\n",
       "      <td>440.77</td>\n",
       "      <td>362.95</td>\n",
       "      <td>207.27</td>\n",
       "      <td>...</td>\n",
       "      <td>17.82</td>\n",
       "      <td>-51.66</td>\n",
       "      <td>-48.29</td>\n",
       "      <td>-59.99</td>\n",
       "      <td>-82.10</td>\n",
       "      <td>-174.54</td>\n",
       "      <td>-95.23</td>\n",
       "      <td>-162.68</td>\n",
       "      <td>-36.79</td>\n",
       "      <td>30.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-826.00</td>\n",
       "      <td>-827.31</td>\n",
       "      <td>-846.12</td>\n",
       "      <td>-836.03</td>\n",
       "      <td>-745.50</td>\n",
       "      <td>-784.69</td>\n",
       "      <td>-791.22</td>\n",
       "      <td>-746.50</td>\n",
       "      <td>-709.53</td>\n",
       "      <td>...</td>\n",
       "      <td>122.34</td>\n",
       "      <td>93.03</td>\n",
       "      <td>93.03</td>\n",
       "      <td>68.81</td>\n",
       "      <td>9.81</td>\n",
       "      <td>20.75</td>\n",
       "      <td>20.25</td>\n",
       "      <td>-120.81</td>\n",
       "      <td>-257.56</td>\n",
       "      <td>-215.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-39.57</td>\n",
       "      <td>-15.88</td>\n",
       "      <td>-9.16</td>\n",
       "      <td>-6.37</td>\n",
       "      <td>-16.13</td>\n",
       "      <td>-24.05</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>-45.20</td>\n",
       "      <td>-5.04</td>\n",
       "      <td>...</td>\n",
       "      <td>-37.87</td>\n",
       "      <td>-61.85</td>\n",
       "      <td>-27.15</td>\n",
       "      <td>-21.18</td>\n",
       "      <td>-33.76</td>\n",
       "      <td>-85.34</td>\n",
       "      <td>-81.46</td>\n",
       "      <td>-61.98</td>\n",
       "      <td>-69.34</td>\n",
       "      <td>-17.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LABEL   FLUX.1   FLUX.2   FLUX.3   FLUX.4   FLUX.5   FLUX.6   FLUX.7  \\\n",
       "0      1   119.88   100.21    86.46    48.68    46.12    39.39    18.57   \n",
       "1      1  5736.59  5699.98  5717.16  5692.73  5663.83  5631.16  5626.39   \n",
       "2      1   844.48   817.49   770.07   675.01   605.52   499.45   440.77   \n",
       "3      1  -826.00  -827.31  -846.12  -836.03  -745.50  -784.69  -791.22   \n",
       "4      1   -39.57   -15.88    -9.16    -6.37   -16.13   -24.05    -0.90   \n",
       "\n",
       "    FLUX.8   FLUX.9    ...      FLUX.3188  FLUX.3189  FLUX.3190  FLUX.3191  \\\n",
       "0     6.98     6.63    ...          14.52      19.29      14.44      -1.62   \n",
       "1  5569.47  5550.44    ...        -581.91    -984.09   -1230.89   -1600.45   \n",
       "2   362.95   207.27    ...          17.82     -51.66     -48.29     -59.99   \n",
       "3  -746.50  -709.53    ...         122.34      93.03      93.03      68.81   \n",
       "4   -45.20    -5.04    ...         -37.87     -61.85     -27.15     -21.18   \n",
       "\n",
       "   FLUX.3192  FLUX.3193  FLUX.3194  FLUX.3195  FLUX.3196  FLUX.3197  \n",
       "0      13.33      45.50      31.93      35.78     269.43      57.72  \n",
       "1   -1824.53   -2061.17   -2265.98   -2366.19   -2294.86   -2034.72  \n",
       "2     -82.10    -174.54     -95.23    -162.68     -36.79      30.63  \n",
       "3       9.81      20.75      20.25    -120.81    -257.56    -215.41  \n",
       "4     -33.76     -85.34     -81.46     -61.98     -69.34     -17.84  \n",
       "\n",
       "[5 rows x 3198 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### combine the two datasets into one to regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfwhole = pd.concat([df,dftest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5657, 3198)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfwhole.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into training and test using train_test_split 80% train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into a training and test set.\n",
    "Xlr, Xtestlr, ylr, ytestlr = train_test_split(dfwhole.loc[:,'FLUX.1':].values, dfwhole['LABEL'].values, test_size =.5, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.567691763874\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C=1)\n",
    "\n",
    "# Fit the model on the trainng data.\n",
    "clf.fit(Xlr, ylr)\n",
    "# Print the accuracy from the testing data.\n",
    "print(accuracy_score(clf.predict(Xtestlr), ytestlr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Classification Report and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.57      0.72      2810\n",
      "          1       0.01      0.58      0.02        19\n",
      "\n",
      "avg / total       0.99      0.57      0.72      2829\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " Predicted     0   1   All\n",
      "True                     \n",
      "0          1595   8  1603\n",
      "1          1215  11  1226\n",
      "All        2810  19  2829\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "#Print Confusion Matrix\n",
    "print ('\\nClassification Report:\\n', classification_report(ytestlr,clf.predict(Xtestlr)))\n",
    "print ('\\nConfusion Matrix:\\n', pd.crosstab( clf.predict(Xtestlr),ytestlr, rownames=['True'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(Xtestlr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics import roc_auc_score\n",
    "#y_true = np.array([0, 0, 1, 1])\n",
    "#y_scores = np.array([0.1, 0.4, 0.35, 0.8])\n",
    "#roc_auc_score(y_true, y_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_score(clf, x, y, score_func=accuracy_score):\n",
    "    result = 0\n",
    "    nfold = 5\n",
    "    for train, test in KFold(nfold).split(x): # split data into train/test groups, 5 times\n",
    "        clf.fit(x[train], y[train]) # fit\n",
    "        result += score_func(clf.predict(x[test]), y[test]) # evaluate score function on held-out data\n",
    "    return result / nfold # average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.584866318522\n"
     ]
    }
   ],
   "source": [
    "clf2 = LogisticRegression()\n",
    "score = cv_score(clf2, Xlr, ylr)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample through different C parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maxium: 0.5905250320522843\n",
      "Best value for C : 0.001\n"
     ]
    }
   ],
   "source": [
    "#the grid of parameters to search over\n",
    "Cs = [0.001, 0.1, 1, 10, 100]\n",
    "\n",
    "#For C parameters\n",
    "\n",
    "def Parameters_C(Cs):\n",
    "    \"\"\"\n",
    "    Input List of C values\n",
    "    Output Best C value as highest cv_score is tracked \n",
    "    \"\"\"\n",
    "    max_value = 0 \n",
    "    \n",
    "    for parameters in Cs:\n",
    "        logReg = LogisticRegression(C = parameters) #perform Log Reg with C\n",
    "        score = cv_score(logReg, Xlr, ylr) #get average score\n",
    "\n",
    "        if score > max_value:\n",
    "            max_value = score\n",
    "            top_C = parameters\n",
    "        \n",
    "    return max_value, top_C\n",
    "            \n",
    "max_value, top_C = Parameters_C(Cs)\n",
    "\n",
    "print('Maxium: {}'.format(max_value))\n",
    "print('Best value for C : {}'.format(top_C))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.564863909509\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C=top_C)\n",
    "# Fit the model on the trainng data.\n",
    "clf.fit(Xlr, ylr)\n",
    "# Print the accuracy from the testing data.\n",
    "print(accuracy_score(clf.predict(Xtestlr), ytestlr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Do the Logistic Regression on the Kaggle competion split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xlr = df.loc[:,'FLUX.1':].values\n",
    "Xtestlr = dftest.loc[:,'FLUX.1':].values\n",
    "ylr = df['LABEL'].values\n",
    "ytestlr =dftest['LABEL'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5087, 3197)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xlr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.519298245614\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C=top_C)\n",
    "\n",
    "# Fit the model on the trainng data.\n",
    "clf.fit(Xlr, ylr)\n",
    "\n",
    "# Print the accuracy from the testing data.\n",
    "print(accuracy_score(clf.predict(Xtestlr), ytestlr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report and Confusion Matrix on Kaggle Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.52      0.68       565\n",
      "          1       0.01      0.60      0.02         5\n",
      "\n",
      "avg / total       0.98      0.52      0.68       570\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " Predicted    0  1  All\n",
      "True                  \n",
      "0          293  2  295\n",
      "1          272  3  275\n",
      "All        565  5  570\n"
     ]
    }
   ],
   "source": [
    "#Print Confusion Matrix\n",
    "print ('\\nClassification Report:\\n', classification_report(ytestlr,clf.predict(Xtestlr)))\n",
    "print ('\\nConfusion Matrix:\\n', pd.crosstab( clf.predict(Xtestlr),ytestlr, rownames=['True'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now with Normalized Scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and instatiate scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scale = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit and transform normalizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create separate array of Labals before transformation, remove labels from transformable dataset\n",
    "dfwhole_target = dfwhole['LABEL']\n",
    "dfwhole.drop('LABEL',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FLUX.1</th>\n",
       "      <th>FLUX.2</th>\n",
       "      <th>FLUX.3</th>\n",
       "      <th>FLUX.4</th>\n",
       "      <th>FLUX.5</th>\n",
       "      <th>FLUX.6</th>\n",
       "      <th>FLUX.7</th>\n",
       "      <th>FLUX.8</th>\n",
       "      <th>FLUX.9</th>\n",
       "      <th>FLUX.10</th>\n",
       "      <th>...</th>\n",
       "      <th>FLUX.3188</th>\n",
       "      <th>FLUX.3189</th>\n",
       "      <th>FLUX.3190</th>\n",
       "      <th>FLUX.3191</th>\n",
       "      <th>FLUX.3192</th>\n",
       "      <th>FLUX.3193</th>\n",
       "      <th>FLUX.3194</th>\n",
       "      <th>FLUX.3195</th>\n",
       "      <th>FLUX.3196</th>\n",
       "      <th>FLUX.3197</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93.85</td>\n",
       "      <td>83.81</td>\n",
       "      <td>20.10</td>\n",
       "      <td>-26.98</td>\n",
       "      <td>-39.56</td>\n",
       "      <td>-124.71</td>\n",
       "      <td>-135.18</td>\n",
       "      <td>-96.27</td>\n",
       "      <td>-79.89</td>\n",
       "      <td>-160.17</td>\n",
       "      <td>...</td>\n",
       "      <td>-78.07</td>\n",
       "      <td>-102.15</td>\n",
       "      <td>-102.15</td>\n",
       "      <td>25.13</td>\n",
       "      <td>48.57</td>\n",
       "      <td>92.54</td>\n",
       "      <td>39.32</td>\n",
       "      <td>61.42</td>\n",
       "      <td>5.08</td>\n",
       "      <td>-39.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-38.88</td>\n",
       "      <td>-33.83</td>\n",
       "      <td>-58.54</td>\n",
       "      <td>-40.09</td>\n",
       "      <td>-79.31</td>\n",
       "      <td>-72.81</td>\n",
       "      <td>-86.55</td>\n",
       "      <td>-85.33</td>\n",
       "      <td>-83.97</td>\n",
       "      <td>-73.38</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.28</td>\n",
       "      <td>-32.21</td>\n",
       "      <td>-32.21</td>\n",
       "      <td>-24.89</td>\n",
       "      <td>-4.86</td>\n",
       "      <td>0.76</td>\n",
       "      <td>-11.70</td>\n",
       "      <td>6.46</td>\n",
       "      <td>16.00</td>\n",
       "      <td>19.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>532.64</td>\n",
       "      <td>535.92</td>\n",
       "      <td>513.73</td>\n",
       "      <td>496.92</td>\n",
       "      <td>456.45</td>\n",
       "      <td>466.00</td>\n",
       "      <td>464.50</td>\n",
       "      <td>486.39</td>\n",
       "      <td>436.56</td>\n",
       "      <td>484.39</td>\n",
       "      <td>...</td>\n",
       "      <td>-71.69</td>\n",
       "      <td>13.31</td>\n",
       "      <td>13.31</td>\n",
       "      <td>-29.89</td>\n",
       "      <td>-20.88</td>\n",
       "      <td>5.06</td>\n",
       "      <td>-11.80</td>\n",
       "      <td>-28.91</td>\n",
       "      <td>-70.02</td>\n",
       "      <td>-96.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>326.52</td>\n",
       "      <td>347.39</td>\n",
       "      <td>302.35</td>\n",
       "      <td>298.13</td>\n",
       "      <td>317.74</td>\n",
       "      <td>312.70</td>\n",
       "      <td>322.33</td>\n",
       "      <td>311.31</td>\n",
       "      <td>312.42</td>\n",
       "      <td>323.33</td>\n",
       "      <td>...</td>\n",
       "      <td>5.71</td>\n",
       "      <td>-3.73</td>\n",
       "      <td>-3.73</td>\n",
       "      <td>30.05</td>\n",
       "      <td>20.03</td>\n",
       "      <td>-12.67</td>\n",
       "      <td>-8.77</td>\n",
       "      <td>-17.31</td>\n",
       "      <td>-17.35</td>\n",
       "      <td>13.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1107.21</td>\n",
       "      <td>-1112.59</td>\n",
       "      <td>-1118.95</td>\n",
       "      <td>-1095.10</td>\n",
       "      <td>-1057.55</td>\n",
       "      <td>-1034.48</td>\n",
       "      <td>-998.34</td>\n",
       "      <td>-1022.71</td>\n",
       "      <td>-989.57</td>\n",
       "      <td>-970.88</td>\n",
       "      <td>...</td>\n",
       "      <td>-594.37</td>\n",
       "      <td>-401.66</td>\n",
       "      <td>-401.66</td>\n",
       "      <td>-357.24</td>\n",
       "      <td>-443.76</td>\n",
       "      <td>-438.54</td>\n",
       "      <td>-399.71</td>\n",
       "      <td>-384.65</td>\n",
       "      <td>-411.79</td>\n",
       "      <td>-510.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3197 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    FLUX.1   FLUX.2   FLUX.3   FLUX.4   FLUX.5   FLUX.6  FLUX.7   FLUX.8  \\\n",
       "0    93.85    83.81    20.10   -26.98   -39.56  -124.71 -135.18   -96.27   \n",
       "1   -38.88   -33.83   -58.54   -40.09   -79.31   -72.81  -86.55   -85.33   \n",
       "2   532.64   535.92   513.73   496.92   456.45   466.00  464.50   486.39   \n",
       "3   326.52   347.39   302.35   298.13   317.74   312.70  322.33   311.31   \n",
       "4 -1107.21 -1112.59 -1118.95 -1095.10 -1057.55 -1034.48 -998.34 -1022.71   \n",
       "\n",
       "   FLUX.9  FLUX.10    ...      FLUX.3188  FLUX.3189  FLUX.3190  FLUX.3191  \\\n",
       "0  -79.89  -160.17    ...         -78.07    -102.15    -102.15      25.13   \n",
       "1  -83.97   -73.38    ...          -3.28     -32.21     -32.21     -24.89   \n",
       "2  436.56   484.39    ...         -71.69      13.31      13.31     -29.89   \n",
       "3  312.42   323.33    ...           5.71      -3.73      -3.73      30.05   \n",
       "4 -989.57  -970.88    ...        -594.37    -401.66    -401.66    -357.24   \n",
       "\n",
       "   FLUX.3192  FLUX.3193  FLUX.3194  FLUX.3195  FLUX.3196  FLUX.3197  \n",
       "0      48.57      92.54      39.32      61.42       5.08     -39.54  \n",
       "1      -4.86       0.76     -11.70       6.46      16.00      19.93  \n",
       "2     -20.88       5.06     -11.80     -28.91     -70.02     -96.67  \n",
       "3      20.03     -12.67      -8.77     -17.31     -17.35      13.98  \n",
       "4    -443.76    -438.54    -399.71    -384.65    -411.79    -510.54  \n",
       "\n",
       "[5 rows x 3197 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfwhole.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the transformation the column headings are lost, so put them in a place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = dfwhole.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfwhole_scale.columns = column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Whole Dataset \n",
    "dfwhole_scale = scale.fit_transform(dfwhole.as_matrix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert back to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Whole Dataset \n",
    "dfwhole_scale = pd.DataFrame(dfwhole_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfwhole_scale.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FLUX.1</th>\n",
       "      <th>FLUX.2</th>\n",
       "      <th>FLUX.3</th>\n",
       "      <th>FLUX.4</th>\n",
       "      <th>FLUX.5</th>\n",
       "      <th>FLUX.6</th>\n",
       "      <th>FLUX.7</th>\n",
       "      <th>FLUX.8</th>\n",
       "      <th>FLUX.9</th>\n",
       "      <th>FLUX.10</th>\n",
       "      <th>...</th>\n",
       "      <th>FLUX.3188</th>\n",
       "      <th>FLUX.3189</th>\n",
       "      <th>FLUX.3190</th>\n",
       "      <th>FLUX.3191</th>\n",
       "      <th>FLUX.3192</th>\n",
       "      <th>FLUX.3193</th>\n",
       "      <th>FLUX.3194</th>\n",
       "      <th>FLUX.3195</th>\n",
       "      <th>FLUX.3196</th>\n",
       "      <th>FLUX.3197</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.004236</td>\n",
       "      <td>-0.005043</td>\n",
       "      <td>-0.007841</td>\n",
       "      <td>-0.011275</td>\n",
       "      <td>-0.010495</td>\n",
       "      <td>-0.014239</td>\n",
       "      <td>-0.012587</td>\n",
       "      <td>-0.012311</td>\n",
       "      <td>-0.011753</td>\n",
       "      <td>-0.018687</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014546</td>\n",
       "      <td>-0.017118</td>\n",
       "      <td>-0.017280</td>\n",
       "      <td>-0.014300</td>\n",
       "      <td>-0.012122</td>\n",
       "      <td>-0.010372</td>\n",
       "      <td>0.026682</td>\n",
       "      <td>0.031563</td>\n",
       "      <td>0.024062</td>\n",
       "      <td>0.015458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.010624</td>\n",
       "      <td>-0.010631</td>\n",
       "      <td>-0.011558</td>\n",
       "      <td>-0.011886</td>\n",
       "      <td>-0.012282</td>\n",
       "      <td>-0.012002</td>\n",
       "      <td>-0.010493</td>\n",
       "      <td>-0.011816</td>\n",
       "      <td>-0.011954</td>\n",
       "      <td>-0.014080</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011809</td>\n",
       "      <td>-0.015050</td>\n",
       "      <td>-0.015588</td>\n",
       "      <td>-0.015357</td>\n",
       "      <td>-0.013227</td>\n",
       "      <td>-0.012181</td>\n",
       "      <td>0.023712</td>\n",
       "      <td>0.028344</td>\n",
       "      <td>0.024757</td>\n",
       "      <td>0.019690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.016880</td>\n",
       "      <td>0.016432</td>\n",
       "      <td>0.015493</td>\n",
       "      <td>0.013141</td>\n",
       "      <td>0.011802</td>\n",
       "      <td>0.011220</td>\n",
       "      <td>0.013229</td>\n",
       "      <td>0.014076</td>\n",
       "      <td>0.013661</td>\n",
       "      <td>0.015525</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014312</td>\n",
       "      <td>-0.013704</td>\n",
       "      <td>-0.014488</td>\n",
       "      <td>-0.015463</td>\n",
       "      <td>-0.013559</td>\n",
       "      <td>-0.012096</td>\n",
       "      <td>0.023706</td>\n",
       "      <td>0.026272</td>\n",
       "      <td>0.019286</td>\n",
       "      <td>0.011392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.006961</td>\n",
       "      <td>0.007477</td>\n",
       "      <td>0.005501</td>\n",
       "      <td>0.003877</td>\n",
       "      <td>0.005566</td>\n",
       "      <td>0.004613</td>\n",
       "      <td>0.007109</td>\n",
       "      <td>0.006147</td>\n",
       "      <td>0.007552</td>\n",
       "      <td>0.006976</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011480</td>\n",
       "      <td>-0.014208</td>\n",
       "      <td>-0.014900</td>\n",
       "      <td>-0.014196</td>\n",
       "      <td>-0.012712</td>\n",
       "      <td>-0.012446</td>\n",
       "      <td>0.023882</td>\n",
       "      <td>0.026952</td>\n",
       "      <td>0.022636</td>\n",
       "      <td>0.019267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.062035</td>\n",
       "      <td>-0.061872</td>\n",
       "      <td>-0.061682</td>\n",
       "      <td>-0.061053</td>\n",
       "      <td>-0.056257</td>\n",
       "      <td>-0.053449</td>\n",
       "      <td>-0.049746</td>\n",
       "      <td>-0.054268</td>\n",
       "      <td>-0.056517</td>\n",
       "      <td>-0.061718</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033436</td>\n",
       "      <td>-0.025975</td>\n",
       "      <td>-0.024522</td>\n",
       "      <td>-0.022379</td>\n",
       "      <td>-0.022308</td>\n",
       "      <td>-0.020841</td>\n",
       "      <td>0.001127</td>\n",
       "      <td>0.005435</td>\n",
       "      <td>-0.002453</td>\n",
       "      <td>-0.018060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3197 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FLUX.1    FLUX.2    FLUX.3    FLUX.4    FLUX.5    FLUX.6    FLUX.7  \\\n",
       "0 -0.004236 -0.005043 -0.007841 -0.011275 -0.010495 -0.014239 -0.012587   \n",
       "1 -0.010624 -0.010631 -0.011558 -0.011886 -0.012282 -0.012002 -0.010493   \n",
       "2  0.016880  0.016432  0.015493  0.013141  0.011802  0.011220  0.013229   \n",
       "3  0.006961  0.007477  0.005501  0.003877  0.005566  0.004613  0.007109   \n",
       "4 -0.062035 -0.061872 -0.061682 -0.061053 -0.056257 -0.053449 -0.049746   \n",
       "\n",
       "     FLUX.8    FLUX.9   FLUX.10    ...      FLUX.3188  FLUX.3189  FLUX.3190  \\\n",
       "0 -0.012311 -0.011753 -0.018687    ...      -0.014546  -0.017118  -0.017280   \n",
       "1 -0.011816 -0.011954 -0.014080    ...      -0.011809  -0.015050  -0.015588   \n",
       "2  0.014076  0.013661  0.015525    ...      -0.014312  -0.013704  -0.014488   \n",
       "3  0.006147  0.007552  0.006976    ...      -0.011480  -0.014208  -0.014900   \n",
       "4 -0.054268 -0.056517 -0.061718    ...      -0.033436  -0.025975  -0.024522   \n",
       "\n",
       "   FLUX.3191  FLUX.3192  FLUX.3193  FLUX.3194  FLUX.3195  FLUX.3196  FLUX.3197  \n",
       "0  -0.014300  -0.012122  -0.010372   0.026682   0.031563   0.024062   0.015458  \n",
       "1  -0.015357  -0.013227  -0.012181   0.023712   0.028344   0.024757   0.019690  \n",
       "2  -0.015463  -0.013559  -0.012096   0.023706   0.026272   0.019286   0.011392  \n",
       "3  -0.014196  -0.012712  -0.012446   0.023882   0.026952   0.022636   0.019267  \n",
       "4  -0.022379  -0.022308  -0.020841   0.001127   0.005435  -0.002453  -0.018060  \n",
       "\n",
       "[5 rows x 3197 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfwhole_scale.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LABEL\n",
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfwhole_target = pd.DataFrame(dfwhole_target)\n",
    "dfwhole_target.reset_index(inplace=True, drop=True)\n",
    "dfwhole_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfwhole_target.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5657, 3197)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfwhole_scale.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5657, 3198)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_col_merged =pd.concat([dfwhole_target, dfwhole_scale], axis=1)\n",
    "df_col_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>FLUX.1</th>\n",
       "      <th>FLUX.2</th>\n",
       "      <th>FLUX.3</th>\n",
       "      <th>FLUX.4</th>\n",
       "      <th>FLUX.5</th>\n",
       "      <th>FLUX.6</th>\n",
       "      <th>FLUX.7</th>\n",
       "      <th>FLUX.8</th>\n",
       "      <th>FLUX.9</th>\n",
       "      <th>...</th>\n",
       "      <th>FLUX.3188</th>\n",
       "      <th>FLUX.3189</th>\n",
       "      <th>FLUX.3190</th>\n",
       "      <th>FLUX.3191</th>\n",
       "      <th>FLUX.3192</th>\n",
       "      <th>FLUX.3193</th>\n",
       "      <th>FLUX.3194</th>\n",
       "      <th>FLUX.3195</th>\n",
       "      <th>FLUX.3196</th>\n",
       "      <th>FLUX.3197</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.004236</td>\n",
       "      <td>-0.005043</td>\n",
       "      <td>-0.007841</td>\n",
       "      <td>-0.011275</td>\n",
       "      <td>-0.010495</td>\n",
       "      <td>-0.014239</td>\n",
       "      <td>-0.012587</td>\n",
       "      <td>-0.012311</td>\n",
       "      <td>-0.011753</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014546</td>\n",
       "      <td>-0.017118</td>\n",
       "      <td>-0.017280</td>\n",
       "      <td>-0.014300</td>\n",
       "      <td>-0.012122</td>\n",
       "      <td>-0.010372</td>\n",
       "      <td>0.026682</td>\n",
       "      <td>0.031563</td>\n",
       "      <td>0.024062</td>\n",
       "      <td>0.015458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.010624</td>\n",
       "      <td>-0.010631</td>\n",
       "      <td>-0.011558</td>\n",
       "      <td>-0.011886</td>\n",
       "      <td>-0.012282</td>\n",
       "      <td>-0.012002</td>\n",
       "      <td>-0.010493</td>\n",
       "      <td>-0.011816</td>\n",
       "      <td>-0.011954</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011809</td>\n",
       "      <td>-0.015050</td>\n",
       "      <td>-0.015588</td>\n",
       "      <td>-0.015357</td>\n",
       "      <td>-0.013227</td>\n",
       "      <td>-0.012181</td>\n",
       "      <td>0.023712</td>\n",
       "      <td>0.028344</td>\n",
       "      <td>0.024757</td>\n",
       "      <td>0.019690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.016880</td>\n",
       "      <td>0.016432</td>\n",
       "      <td>0.015493</td>\n",
       "      <td>0.013141</td>\n",
       "      <td>0.011802</td>\n",
       "      <td>0.011220</td>\n",
       "      <td>0.013229</td>\n",
       "      <td>0.014076</td>\n",
       "      <td>0.013661</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014312</td>\n",
       "      <td>-0.013704</td>\n",
       "      <td>-0.014488</td>\n",
       "      <td>-0.015463</td>\n",
       "      <td>-0.013559</td>\n",
       "      <td>-0.012096</td>\n",
       "      <td>0.023706</td>\n",
       "      <td>0.026272</td>\n",
       "      <td>0.019286</td>\n",
       "      <td>0.011392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.006961</td>\n",
       "      <td>0.007477</td>\n",
       "      <td>0.005501</td>\n",
       "      <td>0.003877</td>\n",
       "      <td>0.005566</td>\n",
       "      <td>0.004613</td>\n",
       "      <td>0.007109</td>\n",
       "      <td>0.006147</td>\n",
       "      <td>0.007552</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011480</td>\n",
       "      <td>-0.014208</td>\n",
       "      <td>-0.014900</td>\n",
       "      <td>-0.014196</td>\n",
       "      <td>-0.012712</td>\n",
       "      <td>-0.012446</td>\n",
       "      <td>0.023882</td>\n",
       "      <td>0.026952</td>\n",
       "      <td>0.022636</td>\n",
       "      <td>0.019267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.062035</td>\n",
       "      <td>-0.061872</td>\n",
       "      <td>-0.061682</td>\n",
       "      <td>-0.061053</td>\n",
       "      <td>-0.056257</td>\n",
       "      <td>-0.053449</td>\n",
       "      <td>-0.049746</td>\n",
       "      <td>-0.054268</td>\n",
       "      <td>-0.056517</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033436</td>\n",
       "      <td>-0.025975</td>\n",
       "      <td>-0.024522</td>\n",
       "      <td>-0.022379</td>\n",
       "      <td>-0.022308</td>\n",
       "      <td>-0.020841</td>\n",
       "      <td>0.001127</td>\n",
       "      <td>0.005435</td>\n",
       "      <td>-0.002453</td>\n",
       "      <td>-0.018060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LABEL    FLUX.1    FLUX.2    FLUX.3    FLUX.4    FLUX.5    FLUX.6  \\\n",
       "0      1 -0.004236 -0.005043 -0.007841 -0.011275 -0.010495 -0.014239   \n",
       "1      1 -0.010624 -0.010631 -0.011558 -0.011886 -0.012282 -0.012002   \n",
       "2      1  0.016880  0.016432  0.015493  0.013141  0.011802  0.011220   \n",
       "3      1  0.006961  0.007477  0.005501  0.003877  0.005566  0.004613   \n",
       "4      1 -0.062035 -0.061872 -0.061682 -0.061053 -0.056257 -0.053449   \n",
       "\n",
       "     FLUX.7    FLUX.8    FLUX.9    ...      FLUX.3188  FLUX.3189  FLUX.3190  \\\n",
       "0 -0.012587 -0.012311 -0.011753    ...      -0.014546  -0.017118  -0.017280   \n",
       "1 -0.010493 -0.011816 -0.011954    ...      -0.011809  -0.015050  -0.015588   \n",
       "2  0.013229  0.014076  0.013661    ...      -0.014312  -0.013704  -0.014488   \n",
       "3  0.007109  0.006147  0.007552    ...      -0.011480  -0.014208  -0.014900   \n",
       "4 -0.049746 -0.054268 -0.056517    ...      -0.033436  -0.025975  -0.024522   \n",
       "\n",
       "   FLUX.3191  FLUX.3192  FLUX.3193  FLUX.3194  FLUX.3195  FLUX.3196  FLUX.3197  \n",
       "0  -0.014300  -0.012122  -0.010372   0.026682   0.031563   0.024062   0.015458  \n",
       "1  -0.015357  -0.013227  -0.012181   0.023712   0.028344   0.024757   0.019690  \n",
       "2  -0.015463  -0.013559  -0.012096   0.023706   0.026272   0.019286   0.011392  \n",
       "3  -0.014196  -0.012712  -0.012446   0.023882   0.026952   0.022636   0.019267  \n",
       "4  -0.022379  -0.022308  -0.020841   0.001127   0.005435  -0.002453  -0.018060  \n",
       "\n",
       "[5 rows x 3198 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_col_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into a training and test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the logistic model : Test size 60% and random state 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into a training and test set.\n",
    "Xlr, Xtestlr, ylr, ytestlr = train_test_split(df_col_merged.loc[:,'FLUX.1':].values, df_col_merged['LABEL'].values, test_size =.6, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.983505154639\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "\n",
    "# Fit the model on the trainng data.\n",
    "clf.fit(Xlr, ylr)\n",
    "\n",
    "# Print the accuracy from the testing data.\n",
    "print(accuracy_score(clf.predict(Xtestlr), ytestlr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.99      0.99      3374\n",
      "          1       0.00      0.00      0.00        21\n",
      "\n",
      "avg / total       0.99      0.98      0.99      3395\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " Predicted     0   1   All\n",
      "True                     \n",
      "0          3339  21  3360\n",
      "1            35   0    35\n",
      "All        3374  21  3395\n"
     ]
    }
   ],
   "source": [
    "#Print Confusion Matrix\n",
    "print ('\\nClassification Report:\\n', classification_report(ytestlr,clf.predict(Xtestlr)))\n",
    "print ('\\nConfusion Matrix:\\n', pd.crosstab( clf.predict(Xtestlr),ytestlr, rownames=['True'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recall of 0.00 for 1 means the model is predicting for the Non-exoplanet and failing for actual exoplanets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now for the Competition Breakdown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore Star Light Intensity with & without exoPlanet\n",
    "# remove the label data\n",
    "\n",
    "#create separate array of Labels before transformation, remove labels from transformable dataset\n",
    "df_target = df['LABEL']\n",
    "df.drop('LABEL',axis=1,inplace=True)\n",
    "\n",
    "dftest_target = dftest['LABEL']\n",
    "dftest.drop('LABEL',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Competition Split: Fit Transform\n",
    "dftrain_scale = scale.fit_transform(df.as_matrix())\n",
    "dftest_scale = scale.fit_transform(dftest.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Competition Split: Revert to Dataset\n",
    "dftrain_scale = pd.DataFrame(dftrain_scale)\n",
    "dftest_scale = pd.DataFrame(dftest_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.973684210526\n"
     ]
    }
   ],
   "source": [
    "clf_c = LogisticRegression(C=1)\n",
    "\n",
    "# Fit the model on the trainng data.\n",
    "clf_c.fit(dftrain_scale, df_target)\n",
    "\n",
    "# Print the accuracy from the testing data.\n",
    "print(accuracy_score(clf.predict(dftest_scale), dftest_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00      3374\n",
      "          1       0.67      0.10      0.17        21\n",
      "\n",
      "avg / total       0.99      0.99      0.99      3395\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " Predicted     0   1   All\n",
      "True                     \n",
      "0          3373  19  3392\n",
      "1             1   2     3\n",
      "All        3374  21  3395\n"
     ]
    }
   ],
   "source": [
    "#Print Confusion Matrix\n",
    "print ('\\nClassification Report:\\n', classification_report(ytestlr,clf_c.predict(Xtestlr)))\n",
    "print ('\\nConfusion Matrix:\\n', pd.crosstab( clf_c.predict(Xtestlr),ytestlr, rownames=['True'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recall of 0.10 for 1 means the model is predicting for the Non-exoplanet and still failing for actual exoplanets, only 2 out of 21 correctly predicted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets try with Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('exoTrain.csv')\n",
    "dftest = pd.read_csv('exoTest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfall = pd.concat([df,dftest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5657, 3198)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfall.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfall['LABEL'] = dfall['LABEL']-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5615\n",
       "1    2000\n",
       "Name: LABEL, dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate majority and minority classes\n",
    "df_noexo = dfall[dfall['LABEL']==0]\n",
    "df_yesexo = dfall[dfall['LABEL']==1]\n",
    " \n",
    "# Upsample minority class\n",
    "df_yesexo_upsampled = resample(df_yesexo, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=2000,    # to match majority class\n",
    "                                 random_state=42) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_noexo, df_yesexo_upsampled])\n",
    " \n",
    "# Display new class counts\n",
    "df_upsampled['LABEL'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into a training and test set.\n",
    "Xlr, Xtestlr, ylr, ytestlr = train_test_split(df_upsampled.loc[:,'FLUX.1':].values, df_upsampled['LABEL'].values, test_size =.6, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.50      0.64      3417\n",
      "          1       0.35      0.82      0.50      1152\n",
      "\n",
      "avg / total       0.76      0.58      0.60      4569\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " Predicted     0     1   All\n",
      "True                       \n",
      "0          1694   206  1900\n",
      "1          1723   946  2669\n",
      "All        3417  1152  4569\n"
     ]
    }
   ],
   "source": [
    "#Print Confusion Matrix\n",
    "print ('\\nClassification Report:\\n', classification_report(ytestlr,clf_s.predict(Xtestlr)))\n",
    "print ('\\nConfusion Matrix:\\n', pd.crosstab(clf_s.predict(Xtestlr),ytestlr, rownames=['True'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Working with a group of classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign the classifiers \n",
    "svc = SVC(kernel='sigmoid', class_weight='balanced', gamma=1.0)\n",
    "knc = KNeighborsClassifier(n_neighbors=5)\n",
    "mnb = MultinomialNB(alpha=0.2)\n",
    "dtc = DecisionTreeClassifier(min_samples_split=7, random_state=111)\n",
    "lrc = LogisticRegression(solver='liblinear', penalty='l1')\n",
    "rfc = RandomForestClassifier(n_estimators=31, random_state=111)\n",
    "abc = AdaBoostClassifier(n_estimators=62, random_state=111)\n",
    "bc = BaggingClassifier(n_estimators=9, random_state=111)\n",
    "etc = ExtraTreesClassifier(n_estimators=9, random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = {'SVC' : svc,'KN' : knc, 'DT': dtc, 'LR': lrc, 'RF': rfc, 'AdaBoost': abc, 'BgC': bc, 'ETC': etc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(clf, feature_train, labels_train):\n",
    "    \"\"\"create the classfier feeder to fit the features and labels\"\"\"\n",
    "    clf.fit(feature_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_labels(clf, features):\n",
    "    \"\"\"predicted values from the features matrix\"\"\"\n",
    "    return (clf.predict(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:  SVC \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.71      0.72      3417\n",
      "          1       0.22      0.25      0.23      1152\n",
      "\n",
      "avg / total       0.61      0.59      0.60      4569\n",
      "\n",
      "\n",
      "Confusion Matrix:  SVC \n",
      " Predicted     0     1   All\n",
      "True                       \n",
      "0          2415   866  3281\n",
      "1          1002   286  1288\n",
      "All        3417  1152  4569\n",
      "\n",
      "Classification Report:  KN \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99      3417\n",
      "          1       0.94      1.00      0.97      1152\n",
      "\n",
      "avg / total       0.99      0.99      0.99      4569\n",
      "\n",
      "\n",
      "Confusion Matrix:  KN \n",
      " Predicted     0     1   All\n",
      "True                       \n",
      "0          3349     0  3349\n",
      "1            68  1152  1220\n",
      "All        3417  1152  4569\n",
      "\n",
      "Classification Report:  DT \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      0.99      3417\n",
      "          1       0.97      1.00      0.99      1152\n",
      "\n",
      "avg / total       0.99      0.99      0.99      4569\n",
      "\n",
      "\n",
      "Confusion Matrix:  DT \n",
      " Predicted     0     1   All\n",
      "True                       \n",
      "0          3382     0  3382\n",
      "1            35  1152  1187\n",
      "All        3417  1152  4569\n",
      "\n",
      "Classification Report:  LR \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.96      0.97      3417\n",
      "          1       0.89      0.98      0.93      1152\n",
      "\n",
      "avg / total       0.97      0.96      0.96      4569\n",
      "\n",
      "\n",
      "Confusion Matrix:  LR \n",
      " Predicted     0     1   All\n",
      "True                       \n",
      "0          3271    23  3294\n",
      "1           146  1129  1275\n",
      "All        3417  1152  4569\n",
      "\n",
      "Classification Report:  RF \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      3417\n",
      "          1       1.00      1.00      1.00      1152\n",
      "\n",
      "avg / total       1.00      1.00      1.00      4569\n",
      "\n",
      "\n",
      "Confusion Matrix:  RF \n",
      " Predicted     0     1   All\n",
      "True                       \n",
      "0          3415     0  3415\n",
      "1             2  1152  1154\n",
      "All        3417  1152  4569\n",
      "\n",
      "Classification Report:  AdaBoost \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      0.99      3417\n",
      "          1       0.97      1.00      0.99      1152\n",
      "\n",
      "avg / total       0.99      0.99      0.99      4569\n",
      "\n",
      "\n",
      "Confusion Matrix:  AdaBoost \n",
      " Predicted     0     1   All\n",
      "True                       \n",
      "0          3383     0  3383\n",
      "1            34  1152  1186\n",
      "All        3417  1152  4569\n",
      "\n",
      "Classification Report:  BgC \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      3417\n",
      "          1       0.99      1.00      0.99      1152\n",
      "\n",
      "avg / total       1.00      1.00      1.00      4569\n",
      "\n",
      "\n",
      "Confusion Matrix:  BgC \n",
      " Predicted     0     1   All\n",
      "True                       \n",
      "0          3405     0  3405\n",
      "1            12  1152  1164\n",
      "All        3417  1152  4569\n",
      "\n",
      "Classification Report:  ETC \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      3417\n",
      "          1       1.00      1.00      1.00      1152\n",
      "\n",
      "avg / total       1.00      1.00      1.00      4569\n",
      "\n",
      "\n",
      "Confusion Matrix:  ETC \n",
      " Predicted     0     1   All\n",
      "True                       \n",
      "0          3415     0  3415\n",
      "1             2  1152  1154\n",
      "All        3417  1152  4569\n"
     ]
    }
   ],
   "source": [
    "features_train = Xlr\n",
    "labels_train = ylr\n",
    "features_test = Xtestlr\n",
    "labels_test = ytestlr\n",
    "\n",
    "pred_scores = []\n",
    "for k,v in clfs.items():\n",
    "    #print(k)\n",
    "    train_classifier(v, features_train, labels_train)\n",
    "    pred = predict_labels(v,features_test)\n",
    "    pred_scores.append((k, [accuracy_score(labels_test,pred)]))\n",
    "    print ('\\nClassification Report: ', k,'\\n', classification_report(labels_test,pred))\n",
    "    print ('\\nConfusion Matrix: ',k,'\\n', pd.crosstab( pred,labels_test, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With the upsampled dataset for Exoplanets, Random Forest and Extra Trees Classifier came back with good results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.591158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KN</th>\n",
       "      <td>0.985117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>0.992340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.963012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.999562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.992559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BgC</th>\n",
       "      <td>0.997374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ETC</th>\n",
       "      <td>0.999562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Score\n",
       "SVC       0.591158\n",
       "KN        0.985117\n",
       "DT        0.992340\n",
       "LR        0.963012\n",
       "RF        0.999562\n",
       "AdaBoost  0.992559\n",
       "BgC       0.997374\n",
       "ETC       0.999562"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = pd.DataFrame.from_items(pred_scores,orient='index', columns=['Score'])\n",
    "df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let see how that works with a specific set of data that is 100% exoplanets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 42 entries, 0 to 4\n",
      "Columns: 3198 entries, LABEL to FLUX.3197\n",
      "dtypes: float64(3197), int64(1)\n",
      "memory usage: 1.0 MB\n"
     ]
    }
   ],
   "source": [
    "df_yesexo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_testmodel = df_yesexo.loc[:, df.columns != 'LABEL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_100p = predict_labels(v,df_testmodel) # fit for Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_100p.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if up sample is taken only from 1/2 the data as a new 100% training set and we see if the unseen data is modelled correctly? Take the remainder (unseen) to use a 100% test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the exoplanet data 50-50\n",
    "df_yesexo_1sthalf = df_yesexo[:21]\n",
    "df_yesexo_2ndhalf = df_yesexo[21:42]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsample the exoplanet data to 2000 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5615\n",
       "1    2000\n",
       "Name: LABEL, dtype: int64"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upsample exoplanet class\n",
    "df_yesexo_upsampled = resample(df_yesexo_1sthalf, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=2000,    \n",
    "                                 random_state=42) # reproducible results\n",
    " \n",
    "# Combine non-exoplanet class with upsampled exoplanet class\n",
    "df_upsampled = pd.concat([df_noexo, df_yesexo_upsampled])\n",
    " \n",
    "# Display new exoplanet class counts\n",
    "df_upsampled['LABEL'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into a training and test set.\n",
    "Xlr, Xtestlr, ylr, ytestlr = train_test_split(df_upsampled.loc[:,'FLUX.1':].values, df_upsampled['LABEL'].values, test_size =.6, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.22100000e+01,  -1.34100000e+01,  -1.65800000e+01, ...,\n",
       "         -5.43000000e+00,  -2.20000000e+00,  -8.00000000e-02],\n",
       "       [ -2.67210000e+02,  -2.39110000e+02,  -2.33150000e+02, ...,\n",
       "         -7.57050000e+02,  -7.63260000e+02,  -7.69390000e+02],\n",
       "       [ -1.51385000e+03,  -1.48397000e+03,  -1.51553000e+03, ...,\n",
       "          2.55737000e+03,   2.59959000e+03,   2.72262000e+03],\n",
       "       ..., \n",
       "       [ -2.67210000e+02,  -2.39110000e+02,  -2.33150000e+02, ...,\n",
       "         -7.57050000e+02,  -7.63260000e+02,  -7.69390000e+02],\n",
       "       [  9.71800000e+01,   7.08600000e+01,   7.32800000e+01, ...,\n",
       "          1.18300000e+01,   2.68200000e+01,  -1.54400000e+01],\n",
       "       [  8.03300000e+01,   6.81900000e+01,   4.63000000e+01, ...,\n",
       "         -1.95900000e+01,  -1.90900000e+01,   5.95000000e+00]])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:  SVC \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.67      0.68      3417\n",
      "          1       0.13      0.14      0.13      1152\n",
      "\n",
      "avg / total       0.55      0.53      0.54      4569\n",
      "\n",
      "\n",
      "Confusion Matrix:  SVC \n",
      " Predicted     0     1   All\n",
      "True                       \n",
      "0          2279   987  3266\n",
      "1          1138   165  1303\n",
      "All        3417  1152  4569\n",
      "\n",
      "Classification Report:  KN \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      0.99      3417\n",
      "          1       0.97      1.00      0.98      1152\n",
      "\n",
      "avg / total       0.99      0.99      0.99      4569\n",
      "\n",
      "\n",
      "Confusion Matrix:  KN \n",
      " Predicted     0     1   All\n",
      "True                       \n",
      "0          3378     0  3378\n",
      "1            39  1152  1191\n",
      "All        3417  1152  4569\n",
      "\n",
      "Classification Report:  DT \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      1.00      3417\n",
      "          1       0.97      1.00      0.99      1152\n",
      "\n",
      "avg / total       0.99      0.99      0.99      4569\n",
      "\n",
      "\n",
      "Confusion Matrix:  DT \n",
      " Predicted     0     1   All\n",
      "True                       \n",
      "0          3384     0  3384\n",
      "1            33  1152  1185\n",
      "All        3417  1152  4569\n",
      "\n",
      "Classification Report:  LR \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.95      0.98      3417\n",
      "          1       0.88      1.00      0.94      1152\n",
      "\n",
      "avg / total       0.97      0.97      0.97      4569\n",
      "\n",
      "\n",
      "Confusion Matrix:  LR \n",
      " Predicted     0     1   All\n",
      "True                       \n",
      "0          3260     0  3260\n",
      "1           157  1152  1309\n",
      "All        3417  1152  4569\n",
      "\n",
      "Classification Report:  RF \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      3417\n",
      "          1       1.00      1.00      1.00      1152\n",
      "\n",
      "avg / total       1.00      1.00      1.00      4569\n",
      "\n",
      "\n",
      "Confusion Matrix:  RF \n",
      " Predicted     0     1   All\n",
      "True                       \n",
      "0          3417     0  3417\n",
      "1             0  1152  1152\n",
      "All        3417  1152  4569\n",
      "\n",
      "Classification Report:  AdaBoost \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      1.00      3417\n",
      "          1       0.98      1.00      0.99      1152\n",
      "\n",
      "avg / total       0.99      0.99      0.99      4569\n",
      "\n",
      "\n",
      "Confusion Matrix:  AdaBoost \n",
      " Predicted     0     1   All\n",
      "True                       \n",
      "0          3391     0  3391\n",
      "1            26  1152  1178\n",
      "All        3417  1152  4569\n",
      "\n",
      "Classification Report:  BgC \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      3417\n",
      "          1       0.99      1.00      0.99      1152\n",
      "\n",
      "avg / total       1.00      1.00      1.00      4569\n",
      "\n",
      "\n",
      "Confusion Matrix:  BgC \n",
      " Predicted     0     1   All\n",
      "True                       \n",
      "0          3405     0  3405\n",
      "1            12  1152  1164\n",
      "All        3417  1152  4569\n",
      "\n",
      "Classification Report:  ETC \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      3417\n",
      "          1       1.00      1.00      1.00      1152\n",
      "\n",
      "avg / total       1.00      1.00      1.00      4569\n",
      "\n",
      "\n",
      "Confusion Matrix:  ETC \n",
      " Predicted     0     1   All\n",
      "True                       \n",
      "0          3417     0  3417\n",
      "1             0  1152  1152\n",
      "All        3417  1152  4569\n"
     ]
    }
   ],
   "source": [
    "features_train = Xlr\n",
    "labels_train = ylr\n",
    "features_test = Xtestlr\n",
    "labels_test = ytestlr\n",
    "\n",
    "pred_scores = []\n",
    "for k,v in clfs.items():\n",
    "    #print(k)\n",
    "    train_classifier(v, features_train, labels_train)\n",
    "    pred = predict_labels(v,features_test)\n",
    "    pred_scores.append((k, [accuracy_score(labels_test,pred)]))\n",
    "    print ('\\nClassification Report: ', k,'\\n', classification_report(labels_test,pred))\n",
    "    print ('\\nConfusion Matrix: ',k,'\\n', pd.crosstab( pred,labels_test, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see the fit for never seen data, the 2nd half of the exoplanet dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_testmodel = df_yesexo_2ndhalf.loc[:, df_yesexo_2ndhalf.columns != 'LABEL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_testmodel = df_yesexo_1sthalf.loc[:, df_yesexo_1sthalf.columns != 'LABEL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_100p = predict_labels(v,df_testmodel) # fit for Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_100p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report: RFC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      3417\n",
      "          1       1.00      1.00      1.00      1152\n",
      "\n",
      "avg / total       1.00      1.00      1.00      4569\n",
      "\n",
      "\n",
      "Confusion Matrix: RFC\n",
      " Predicted     0     1   All\n",
      "True                       \n",
      "0          3417     0  3417\n",
      "1             0  1152  1152\n",
      "All        3417  1152  4569\n"
     ]
    }
   ],
   "source": [
    "train_classifier(rfc, features_train, labels_train)\n",
    "pred = predict_labels(rfc,features_test)\n",
    "pred_scores.append(('RF', [accuracy_score(labels_test,pred)]))\n",
    "print ('\\nClassification Report: RFC\\n', classification_report(labels_test,pred))\n",
    "print ('\\nConfusion Matrix: RFC\\n', pd.crosstab( pred,labels_test, rownames=['True'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_testmodel = df_yesexo_2ndhalf.loc[:, df_yesexo_2ndhalf.columns != 'LABEL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FLUX.1</th>\n",
       "      <th>FLUX.2</th>\n",
       "      <th>FLUX.3</th>\n",
       "      <th>FLUX.4</th>\n",
       "      <th>FLUX.5</th>\n",
       "      <th>FLUX.6</th>\n",
       "      <th>FLUX.7</th>\n",
       "      <th>FLUX.8</th>\n",
       "      <th>FLUX.9</th>\n",
       "      <th>FLUX.10</th>\n",
       "      <th>...</th>\n",
       "      <th>FLUX.3188</th>\n",
       "      <th>FLUX.3189</th>\n",
       "      <th>FLUX.3190</th>\n",
       "      <th>FLUX.3191</th>\n",
       "      <th>FLUX.3192</th>\n",
       "      <th>FLUX.3193</th>\n",
       "      <th>FLUX.3194</th>\n",
       "      <th>FLUX.3195</th>\n",
       "      <th>FLUX.3196</th>\n",
       "      <th>FLUX.3197</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2053.62</td>\n",
       "      <td>2126.05</td>\n",
       "      <td>2146.33</td>\n",
       "      <td>2159.84</td>\n",
       "      <td>2237.59</td>\n",
       "      <td>2236.12</td>\n",
       "      <td>2244.47</td>\n",
       "      <td>2279.61</td>\n",
       "      <td>2288.22</td>\n",
       "      <td>2221.22</td>\n",
       "      <td>...</td>\n",
       "      <td>1832.59</td>\n",
       "      <td>1935.53</td>\n",
       "      <td>1965.84</td>\n",
       "      <td>2094.19</td>\n",
       "      <td>2212.52</td>\n",
       "      <td>2292.64</td>\n",
       "      <td>2454.48</td>\n",
       "      <td>2568.16</td>\n",
       "      <td>2625.45</td>\n",
       "      <td>2578.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-48.48</td>\n",
       "      <td>-22.95</td>\n",
       "      <td>11.15</td>\n",
       "      <td>-70.04</td>\n",
       "      <td>-120.34</td>\n",
       "      <td>-150.04</td>\n",
       "      <td>-309.38</td>\n",
       "      <td>-160.73</td>\n",
       "      <td>-201.41</td>\n",
       "      <td>-303.71</td>\n",
       "      <td>...</td>\n",
       "      <td>90.70</td>\n",
       "      <td>-20.01</td>\n",
       "      <td>-62.12</td>\n",
       "      <td>-45.96</td>\n",
       "      <td>-52.40</td>\n",
       "      <td>-4.93</td>\n",
       "      <td>26.74</td>\n",
       "      <td>21.43</td>\n",
       "      <td>145.30</td>\n",
       "      <td>197.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>145.84</td>\n",
       "      <td>137.82</td>\n",
       "      <td>96.99</td>\n",
       "      <td>17.09</td>\n",
       "      <td>-73.79</td>\n",
       "      <td>-157.79</td>\n",
       "      <td>-267.71</td>\n",
       "      <td>-365.91</td>\n",
       "      <td>-385.07</td>\n",
       "      <td>-423.68</td>\n",
       "      <td>...</td>\n",
       "      <td>62.76</td>\n",
       "      <td>101.24</td>\n",
       "      <td>98.13</td>\n",
       "      <td>112.51</td>\n",
       "      <td>95.77</td>\n",
       "      <td>127.98</td>\n",
       "      <td>67.51</td>\n",
       "      <td>91.24</td>\n",
       "      <td>40.40</td>\n",
       "      <td>-10.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>207.37</td>\n",
       "      <td>195.04</td>\n",
       "      <td>150.45</td>\n",
       "      <td>135.34</td>\n",
       "      <td>104.90</td>\n",
       "      <td>59.79</td>\n",
       "      <td>42.85</td>\n",
       "      <td>52.74</td>\n",
       "      <td>18.38</td>\n",
       "      <td>-8.13</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.21</td>\n",
       "      <td>-43.43</td>\n",
       "      <td>-14.77</td>\n",
       "      <td>-22.27</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>19.46</td>\n",
       "      <td>9.32</td>\n",
       "      <td>23.55</td>\n",
       "      <td>-4.73</td>\n",
       "      <td>11.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>304.50</td>\n",
       "      <td>275.94</td>\n",
       "      <td>269.24</td>\n",
       "      <td>248.51</td>\n",
       "      <td>194.88</td>\n",
       "      <td>167.80</td>\n",
       "      <td>139.13</td>\n",
       "      <td>149.36</td>\n",
       "      <td>100.97</td>\n",
       "      <td>59.58</td>\n",
       "      <td>...</td>\n",
       "      <td>4.21</td>\n",
       "      <td>3.53</td>\n",
       "      <td>-5.13</td>\n",
       "      <td>14.56</td>\n",
       "      <td>-1.44</td>\n",
       "      <td>-10.73</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-2.89</td>\n",
       "      <td>40.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3197 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FLUX.1   FLUX.2   FLUX.3   FLUX.4   FLUX.5   FLUX.6   FLUX.7   FLUX.8  \\\n",
       "21  2053.62  2126.05  2146.33  2159.84  2237.59  2236.12  2244.47  2279.61   \n",
       "22   -48.48   -22.95    11.15   -70.04  -120.34  -150.04  -309.38  -160.73   \n",
       "23   145.84   137.82    96.99    17.09   -73.79  -157.79  -267.71  -365.91   \n",
       "24   207.37   195.04   150.45   135.34   104.90    59.79    42.85    52.74   \n",
       "25   304.50   275.94   269.24   248.51   194.88   167.80   139.13   149.36   \n",
       "\n",
       "     FLUX.9  FLUX.10    ...      FLUX.3188  FLUX.3189  FLUX.3190  FLUX.3191  \\\n",
       "21  2288.22  2221.22    ...        1832.59    1935.53    1965.84    2094.19   \n",
       "22  -201.41  -303.71    ...          90.70     -20.01     -62.12     -45.96   \n",
       "23  -385.07  -423.68    ...          62.76     101.24      98.13     112.51   \n",
       "24    18.38    -8.13    ...         -13.21     -43.43     -14.77     -22.27   \n",
       "25   100.97    59.58    ...           4.21       3.53      -5.13      14.56   \n",
       "\n",
       "    FLUX.3192  FLUX.3193  FLUX.3194  FLUX.3195  FLUX.3196  FLUX.3197  \n",
       "21    2212.52    2292.64    2454.48    2568.16    2625.45    2578.80  \n",
       "22     -52.40      -4.93      26.74      21.43     145.30     197.20  \n",
       "23      95.77     127.98      67.51      91.24      40.40     -10.80  \n",
       "24      -0.04      19.46       9.32      23.55      -4.73      11.82  \n",
       "25      -1.44     -10.73       3.49       0.18      -2.89      40.34  \n",
       "\n",
       "[5 rows x 3197 columns]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_testmodel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_100p = predict_labels(rfc,df_testmodel) # fit for Random Forest Classifier\n",
    "pred_100p.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FLUX.1</th>\n",
       "      <th>FLUX.2</th>\n",
       "      <th>FLUX.3</th>\n",
       "      <th>FLUX.4</th>\n",
       "      <th>FLUX.5</th>\n",
       "      <th>FLUX.6</th>\n",
       "      <th>FLUX.7</th>\n",
       "      <th>FLUX.8</th>\n",
       "      <th>FLUX.9</th>\n",
       "      <th>FLUX.10</th>\n",
       "      <th>...</th>\n",
       "      <th>FLUX.3188</th>\n",
       "      <th>FLUX.3189</th>\n",
       "      <th>FLUX.3190</th>\n",
       "      <th>FLUX.3191</th>\n",
       "      <th>FLUX.3192</th>\n",
       "      <th>FLUX.3193</th>\n",
       "      <th>FLUX.3194</th>\n",
       "      <th>FLUX.3195</th>\n",
       "      <th>FLUX.3196</th>\n",
       "      <th>FLUX.3197</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93.85</td>\n",
       "      <td>83.81</td>\n",
       "      <td>20.10</td>\n",
       "      <td>-26.98</td>\n",
       "      <td>-39.56</td>\n",
       "      <td>-124.71</td>\n",
       "      <td>-135.18</td>\n",
       "      <td>-96.27</td>\n",
       "      <td>-79.89</td>\n",
       "      <td>-160.17</td>\n",
       "      <td>...</td>\n",
       "      <td>-78.07</td>\n",
       "      <td>-102.15</td>\n",
       "      <td>-102.15</td>\n",
       "      <td>25.13</td>\n",
       "      <td>48.57</td>\n",
       "      <td>92.54</td>\n",
       "      <td>39.32</td>\n",
       "      <td>61.42</td>\n",
       "      <td>5.08</td>\n",
       "      <td>-39.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-38.88</td>\n",
       "      <td>-33.83</td>\n",
       "      <td>-58.54</td>\n",
       "      <td>-40.09</td>\n",
       "      <td>-79.31</td>\n",
       "      <td>-72.81</td>\n",
       "      <td>-86.55</td>\n",
       "      <td>-85.33</td>\n",
       "      <td>-83.97</td>\n",
       "      <td>-73.38</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.28</td>\n",
       "      <td>-32.21</td>\n",
       "      <td>-32.21</td>\n",
       "      <td>-24.89</td>\n",
       "      <td>-4.86</td>\n",
       "      <td>0.76</td>\n",
       "      <td>-11.70</td>\n",
       "      <td>6.46</td>\n",
       "      <td>16.00</td>\n",
       "      <td>19.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>532.64</td>\n",
       "      <td>535.92</td>\n",
       "      <td>513.73</td>\n",
       "      <td>496.92</td>\n",
       "      <td>456.45</td>\n",
       "      <td>466.00</td>\n",
       "      <td>464.50</td>\n",
       "      <td>486.39</td>\n",
       "      <td>436.56</td>\n",
       "      <td>484.39</td>\n",
       "      <td>...</td>\n",
       "      <td>-71.69</td>\n",
       "      <td>13.31</td>\n",
       "      <td>13.31</td>\n",
       "      <td>-29.89</td>\n",
       "      <td>-20.88</td>\n",
       "      <td>5.06</td>\n",
       "      <td>-11.80</td>\n",
       "      <td>-28.91</td>\n",
       "      <td>-70.02</td>\n",
       "      <td>-96.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>326.52</td>\n",
       "      <td>347.39</td>\n",
       "      <td>302.35</td>\n",
       "      <td>298.13</td>\n",
       "      <td>317.74</td>\n",
       "      <td>312.70</td>\n",
       "      <td>322.33</td>\n",
       "      <td>311.31</td>\n",
       "      <td>312.42</td>\n",
       "      <td>323.33</td>\n",
       "      <td>...</td>\n",
       "      <td>5.71</td>\n",
       "      <td>-3.73</td>\n",
       "      <td>-3.73</td>\n",
       "      <td>30.05</td>\n",
       "      <td>20.03</td>\n",
       "      <td>-12.67</td>\n",
       "      <td>-8.77</td>\n",
       "      <td>-17.31</td>\n",
       "      <td>-17.35</td>\n",
       "      <td>13.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1107.21</td>\n",
       "      <td>-1112.59</td>\n",
       "      <td>-1118.95</td>\n",
       "      <td>-1095.10</td>\n",
       "      <td>-1057.55</td>\n",
       "      <td>-1034.48</td>\n",
       "      <td>-998.34</td>\n",
       "      <td>-1022.71</td>\n",
       "      <td>-989.57</td>\n",
       "      <td>-970.88</td>\n",
       "      <td>...</td>\n",
       "      <td>-594.37</td>\n",
       "      <td>-401.66</td>\n",
       "      <td>-401.66</td>\n",
       "      <td>-357.24</td>\n",
       "      <td>-443.76</td>\n",
       "      <td>-438.54</td>\n",
       "      <td>-399.71</td>\n",
       "      <td>-384.65</td>\n",
       "      <td>-411.79</td>\n",
       "      <td>-510.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3197 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    FLUX.1   FLUX.2   FLUX.3   FLUX.4   FLUX.5   FLUX.6  FLUX.7   FLUX.8  \\\n",
       "0    93.85    83.81    20.10   -26.98   -39.56  -124.71 -135.18   -96.27   \n",
       "1   -38.88   -33.83   -58.54   -40.09   -79.31   -72.81  -86.55   -85.33   \n",
       "2   532.64   535.92   513.73   496.92   456.45   466.00  464.50   486.39   \n",
       "3   326.52   347.39   302.35   298.13   317.74   312.70  322.33   311.31   \n",
       "4 -1107.21 -1112.59 -1118.95 -1095.10 -1057.55 -1034.48 -998.34 -1022.71   \n",
       "\n",
       "   FLUX.9  FLUX.10    ...      FLUX.3188  FLUX.3189  FLUX.3190  FLUX.3191  \\\n",
       "0  -79.89  -160.17    ...         -78.07    -102.15    -102.15      25.13   \n",
       "1  -83.97   -73.38    ...          -3.28     -32.21     -32.21     -24.89   \n",
       "2  436.56   484.39    ...         -71.69      13.31      13.31     -29.89   \n",
       "3  312.42   323.33    ...           5.71      -3.73      -3.73      30.05   \n",
       "4 -989.57  -970.88    ...        -594.37    -401.66    -401.66    -357.24   \n",
       "\n",
       "   FLUX.3192  FLUX.3193  FLUX.3194  FLUX.3195  FLUX.3196  FLUX.3197  \n",
       "0      48.57      92.54      39.32      61.42       5.08     -39.54  \n",
       "1      -4.86       0.76     -11.70       6.46      16.00      19.93  \n",
       "2     -20.88       5.06     -11.80     -28.91     -70.02     -96.67  \n",
       "3      20.03     -12.67      -8.77     -17.31     -17.35      13.98  \n",
       "4    -443.76    -438.54    -399.71    -384.65    -411.79    -510.54  \n",
       "\n",
       "[5 rows x 3197 columns]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_testmodel = df_yesexo_1sthalf.loc[:, df_yesexo_1sthalf.columns != 'LABEL']\n",
    "df_testmodel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_100p = predict_labels(rfc,df_testmodel) # fit for Random Forest Classifier\n",
    "pred_100p.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK so it passes the 100% predictable test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1152"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_2 = predict_labels(rfc,features_test)\n",
    "pred_2.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>FLUX.1</th>\n",
       "      <th>FLUX.2</th>\n",
       "      <th>FLUX.3</th>\n",
       "      <th>FLUX.4</th>\n",
       "      <th>FLUX.5</th>\n",
       "      <th>FLUX.6</th>\n",
       "      <th>FLUX.7</th>\n",
       "      <th>FLUX.8</th>\n",
       "      <th>FLUX.9</th>\n",
       "      <th>...</th>\n",
       "      <th>FLUX.3188</th>\n",
       "      <th>FLUX.3189</th>\n",
       "      <th>FLUX.3190</th>\n",
       "      <th>FLUX.3191</th>\n",
       "      <th>FLUX.3192</th>\n",
       "      <th>FLUX.3193</th>\n",
       "      <th>FLUX.3194</th>\n",
       "      <th>FLUX.3195</th>\n",
       "      <th>FLUX.3196</th>\n",
       "      <th>FLUX.3197</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>119.88</td>\n",
       "      <td>100.21</td>\n",
       "      <td>86.46</td>\n",
       "      <td>48.68</td>\n",
       "      <td>46.12</td>\n",
       "      <td>39.39</td>\n",
       "      <td>18.57</td>\n",
       "      <td>6.98</td>\n",
       "      <td>6.63</td>\n",
       "      <td>...</td>\n",
       "      <td>14.52</td>\n",
       "      <td>19.29</td>\n",
       "      <td>14.44</td>\n",
       "      <td>-1.62</td>\n",
       "      <td>13.33</td>\n",
       "      <td>45.50</td>\n",
       "      <td>31.93</td>\n",
       "      <td>35.78</td>\n",
       "      <td>269.43</td>\n",
       "      <td>57.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5736.59</td>\n",
       "      <td>5699.98</td>\n",
       "      <td>5717.16</td>\n",
       "      <td>5692.73</td>\n",
       "      <td>5663.83</td>\n",
       "      <td>5631.16</td>\n",
       "      <td>5626.39</td>\n",
       "      <td>5569.47</td>\n",
       "      <td>5550.44</td>\n",
       "      <td>...</td>\n",
       "      <td>-581.91</td>\n",
       "      <td>-984.09</td>\n",
       "      <td>-1230.89</td>\n",
       "      <td>-1600.45</td>\n",
       "      <td>-1824.53</td>\n",
       "      <td>-2061.17</td>\n",
       "      <td>-2265.98</td>\n",
       "      <td>-2366.19</td>\n",
       "      <td>-2294.86</td>\n",
       "      <td>-2034.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>844.48</td>\n",
       "      <td>817.49</td>\n",
       "      <td>770.07</td>\n",
       "      <td>675.01</td>\n",
       "      <td>605.52</td>\n",
       "      <td>499.45</td>\n",
       "      <td>440.77</td>\n",
       "      <td>362.95</td>\n",
       "      <td>207.27</td>\n",
       "      <td>...</td>\n",
       "      <td>17.82</td>\n",
       "      <td>-51.66</td>\n",
       "      <td>-48.29</td>\n",
       "      <td>-59.99</td>\n",
       "      <td>-82.10</td>\n",
       "      <td>-174.54</td>\n",
       "      <td>-95.23</td>\n",
       "      <td>-162.68</td>\n",
       "      <td>-36.79</td>\n",
       "      <td>30.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>-826.00</td>\n",
       "      <td>-827.31</td>\n",
       "      <td>-846.12</td>\n",
       "      <td>-836.03</td>\n",
       "      <td>-745.50</td>\n",
       "      <td>-784.69</td>\n",
       "      <td>-791.22</td>\n",
       "      <td>-746.50</td>\n",
       "      <td>-709.53</td>\n",
       "      <td>...</td>\n",
       "      <td>122.34</td>\n",
       "      <td>93.03</td>\n",
       "      <td>93.03</td>\n",
       "      <td>68.81</td>\n",
       "      <td>9.81</td>\n",
       "      <td>20.75</td>\n",
       "      <td>20.25</td>\n",
       "      <td>-120.81</td>\n",
       "      <td>-257.56</td>\n",
       "      <td>-215.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-39.57</td>\n",
       "      <td>-15.88</td>\n",
       "      <td>-9.16</td>\n",
       "      <td>-6.37</td>\n",
       "      <td>-16.13</td>\n",
       "      <td>-24.05</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>-45.20</td>\n",
       "      <td>-5.04</td>\n",
       "      <td>...</td>\n",
       "      <td>-37.87</td>\n",
       "      <td>-61.85</td>\n",
       "      <td>-27.15</td>\n",
       "      <td>-21.18</td>\n",
       "      <td>-33.76</td>\n",
       "      <td>-85.34</td>\n",
       "      <td>-81.46</td>\n",
       "      <td>-61.98</td>\n",
       "      <td>-69.34</td>\n",
       "      <td>-17.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LABEL   FLUX.1   FLUX.2   FLUX.3   FLUX.4   FLUX.5   FLUX.6   FLUX.7  \\\n",
       "0      2   119.88   100.21    86.46    48.68    46.12    39.39    18.57   \n",
       "1      2  5736.59  5699.98  5717.16  5692.73  5663.83  5631.16  5626.39   \n",
       "2      2   844.48   817.49   770.07   675.01   605.52   499.45   440.77   \n",
       "3      2  -826.00  -827.31  -846.12  -836.03  -745.50  -784.69  -791.22   \n",
       "4      2   -39.57   -15.88    -9.16    -6.37   -16.13   -24.05    -0.90   \n",
       "\n",
       "    FLUX.8   FLUX.9    ...      FLUX.3188  FLUX.3189  FLUX.3190  FLUX.3191  \\\n",
       "0     6.98     6.63    ...          14.52      19.29      14.44      -1.62   \n",
       "1  5569.47  5550.44    ...        -581.91    -984.09   -1230.89   -1600.45   \n",
       "2   362.95   207.27    ...          17.82     -51.66     -48.29     -59.99   \n",
       "3  -746.50  -709.53    ...         122.34      93.03      93.03      68.81   \n",
       "4   -45.20    -5.04    ...         -37.87     -61.85     -27.15     -21.18   \n",
       "\n",
       "   FLUX.3192  FLUX.3193  FLUX.3194  FLUX.3195  FLUX.3196  FLUX.3197  \n",
       "0      13.33      45.50      31.93      35.78     269.43      57.72  \n",
       "1   -1824.53   -2061.17   -2265.98   -2366.19   -2294.86   -2034.72  \n",
       "2     -82.10    -174.54     -95.23    -162.68     -36.79      30.63  \n",
       "3       9.81      20.75      20.25    -120.81    -257.56    -215.41  \n",
       "4     -33.76     -85.34     -81.46     -61.98     -69.34     -17.84  \n",
       "\n",
       "[5 rows x 3198 columns]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Against the original Kaggle test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dftest_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest_features = dftest.loc[:,'FLUX.1':].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_3 = predict_labels(rfc,dftest_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report: RFC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00       565\n",
      "          1       0.00      0.00      0.00         5\n",
      "\n",
      "avg / total       0.98      0.99      0.99       570\n",
      "\n",
      "\n",
      "Confusion Matrix: RFC\n",
      " Predicted    0  1  All\n",
      "True                  \n",
      "0          565  5  570\n",
      "All        565  5  570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print ('\\nClassification Report: RFC\\n', classification_report(dftest_target,pred_3))\n",
    "print ('\\nConfusion Matrix: RFC\\n', pd.crosstab( pred_3,dftest_target, rownames=['True'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
