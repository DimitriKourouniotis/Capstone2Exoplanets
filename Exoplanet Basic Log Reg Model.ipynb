{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in CSV files. The Test and Train split is an element of the Kaggle compeition source of these files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('exoTrain.csv')\n",
    "dftest = pd.read_csv('exoTest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>FLUX.1</th>\n",
       "      <th>FLUX.2</th>\n",
       "      <th>FLUX.3</th>\n",
       "      <th>FLUX.4</th>\n",
       "      <th>FLUX.5</th>\n",
       "      <th>FLUX.6</th>\n",
       "      <th>FLUX.7</th>\n",
       "      <th>FLUX.8</th>\n",
       "      <th>FLUX.9</th>\n",
       "      <th>...</th>\n",
       "      <th>FLUX.3188</th>\n",
       "      <th>FLUX.3189</th>\n",
       "      <th>FLUX.3190</th>\n",
       "      <th>FLUX.3191</th>\n",
       "      <th>FLUX.3192</th>\n",
       "      <th>FLUX.3193</th>\n",
       "      <th>FLUX.3194</th>\n",
       "      <th>FLUX.3195</th>\n",
       "      <th>FLUX.3196</th>\n",
       "      <th>FLUX.3197</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>93.85</td>\n",
       "      <td>83.81</td>\n",
       "      <td>20.10</td>\n",
       "      <td>-26.98</td>\n",
       "      <td>-39.56</td>\n",
       "      <td>-124.71</td>\n",
       "      <td>-135.18</td>\n",
       "      <td>-96.27</td>\n",
       "      <td>-79.89</td>\n",
       "      <td>...</td>\n",
       "      <td>-78.07</td>\n",
       "      <td>-102.15</td>\n",
       "      <td>-102.15</td>\n",
       "      <td>25.13</td>\n",
       "      <td>48.57</td>\n",
       "      <td>92.54</td>\n",
       "      <td>39.32</td>\n",
       "      <td>61.42</td>\n",
       "      <td>5.08</td>\n",
       "      <td>-39.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-38.88</td>\n",
       "      <td>-33.83</td>\n",
       "      <td>-58.54</td>\n",
       "      <td>-40.09</td>\n",
       "      <td>-79.31</td>\n",
       "      <td>-72.81</td>\n",
       "      <td>-86.55</td>\n",
       "      <td>-85.33</td>\n",
       "      <td>-83.97</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.28</td>\n",
       "      <td>-32.21</td>\n",
       "      <td>-32.21</td>\n",
       "      <td>-24.89</td>\n",
       "      <td>-4.86</td>\n",
       "      <td>0.76</td>\n",
       "      <td>-11.70</td>\n",
       "      <td>6.46</td>\n",
       "      <td>16.00</td>\n",
       "      <td>19.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>532.64</td>\n",
       "      <td>535.92</td>\n",
       "      <td>513.73</td>\n",
       "      <td>496.92</td>\n",
       "      <td>456.45</td>\n",
       "      <td>466.00</td>\n",
       "      <td>464.50</td>\n",
       "      <td>486.39</td>\n",
       "      <td>436.56</td>\n",
       "      <td>...</td>\n",
       "      <td>-71.69</td>\n",
       "      <td>13.31</td>\n",
       "      <td>13.31</td>\n",
       "      <td>-29.89</td>\n",
       "      <td>-20.88</td>\n",
       "      <td>5.06</td>\n",
       "      <td>-11.80</td>\n",
       "      <td>-28.91</td>\n",
       "      <td>-70.02</td>\n",
       "      <td>-96.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>326.52</td>\n",
       "      <td>347.39</td>\n",
       "      <td>302.35</td>\n",
       "      <td>298.13</td>\n",
       "      <td>317.74</td>\n",
       "      <td>312.70</td>\n",
       "      <td>322.33</td>\n",
       "      <td>311.31</td>\n",
       "      <td>312.42</td>\n",
       "      <td>...</td>\n",
       "      <td>5.71</td>\n",
       "      <td>-3.73</td>\n",
       "      <td>-3.73</td>\n",
       "      <td>30.05</td>\n",
       "      <td>20.03</td>\n",
       "      <td>-12.67</td>\n",
       "      <td>-8.77</td>\n",
       "      <td>-17.31</td>\n",
       "      <td>-17.35</td>\n",
       "      <td>13.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1107.21</td>\n",
       "      <td>-1112.59</td>\n",
       "      <td>-1118.95</td>\n",
       "      <td>-1095.10</td>\n",
       "      <td>-1057.55</td>\n",
       "      <td>-1034.48</td>\n",
       "      <td>-998.34</td>\n",
       "      <td>-1022.71</td>\n",
       "      <td>-989.57</td>\n",
       "      <td>...</td>\n",
       "      <td>-594.37</td>\n",
       "      <td>-401.66</td>\n",
       "      <td>-401.66</td>\n",
       "      <td>-357.24</td>\n",
       "      <td>-443.76</td>\n",
       "      <td>-438.54</td>\n",
       "      <td>-399.71</td>\n",
       "      <td>-384.65</td>\n",
       "      <td>-411.79</td>\n",
       "      <td>-510.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LABEL   FLUX.1   FLUX.2   FLUX.3   FLUX.4   FLUX.5   FLUX.6  FLUX.7  \\\n",
       "0      2    93.85    83.81    20.10   -26.98   -39.56  -124.71 -135.18   \n",
       "1      2   -38.88   -33.83   -58.54   -40.09   -79.31   -72.81  -86.55   \n",
       "2      2   532.64   535.92   513.73   496.92   456.45   466.00  464.50   \n",
       "3      2   326.52   347.39   302.35   298.13   317.74   312.70  322.33   \n",
       "4      2 -1107.21 -1112.59 -1118.95 -1095.10 -1057.55 -1034.48 -998.34   \n",
       "\n",
       "    FLUX.8  FLUX.9    ...      FLUX.3188  FLUX.3189  FLUX.3190  FLUX.3191  \\\n",
       "0   -96.27  -79.89    ...         -78.07    -102.15    -102.15      25.13   \n",
       "1   -85.33  -83.97    ...          -3.28     -32.21     -32.21     -24.89   \n",
       "2   486.39  436.56    ...         -71.69      13.31      13.31     -29.89   \n",
       "3   311.31  312.42    ...           5.71      -3.73      -3.73      30.05   \n",
       "4 -1022.71 -989.57    ...        -594.37    -401.66    -401.66    -357.24   \n",
       "\n",
       "   FLUX.3192  FLUX.3193  FLUX.3194  FLUX.3195  FLUX.3196  FLUX.3197  \n",
       "0      48.57      92.54      39.32      61.42       5.08     -39.54  \n",
       "1      -4.86       0.76     -11.70       6.46      16.00      19.93  \n",
       "2     -20.88       5.06     -11.80     -28.91     -70.02     -96.67  \n",
       "3      20.03     -12.67      -8.77     -17.31     -17.35      13.98  \n",
       "4    -443.76    -438.54    -399.71    -384.65    -411.79    -510.54  \n",
       "\n",
       "[5 rows x 3198 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>FLUX.1</th>\n",
       "      <th>FLUX.2</th>\n",
       "      <th>FLUX.3</th>\n",
       "      <th>FLUX.4</th>\n",
       "      <th>FLUX.5</th>\n",
       "      <th>FLUX.6</th>\n",
       "      <th>FLUX.7</th>\n",
       "      <th>FLUX.8</th>\n",
       "      <th>FLUX.9</th>\n",
       "      <th>...</th>\n",
       "      <th>FLUX.3188</th>\n",
       "      <th>FLUX.3189</th>\n",
       "      <th>FLUX.3190</th>\n",
       "      <th>FLUX.3191</th>\n",
       "      <th>FLUX.3192</th>\n",
       "      <th>FLUX.3193</th>\n",
       "      <th>FLUX.3194</th>\n",
       "      <th>FLUX.3195</th>\n",
       "      <th>FLUX.3196</th>\n",
       "      <th>FLUX.3197</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>119.88</td>\n",
       "      <td>100.21</td>\n",
       "      <td>86.46</td>\n",
       "      <td>48.68</td>\n",
       "      <td>46.12</td>\n",
       "      <td>39.39</td>\n",
       "      <td>18.57</td>\n",
       "      <td>6.98</td>\n",
       "      <td>6.63</td>\n",
       "      <td>...</td>\n",
       "      <td>14.52</td>\n",
       "      <td>19.29</td>\n",
       "      <td>14.44</td>\n",
       "      <td>-1.62</td>\n",
       "      <td>13.33</td>\n",
       "      <td>45.50</td>\n",
       "      <td>31.93</td>\n",
       "      <td>35.78</td>\n",
       "      <td>269.43</td>\n",
       "      <td>57.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5736.59</td>\n",
       "      <td>5699.98</td>\n",
       "      <td>5717.16</td>\n",
       "      <td>5692.73</td>\n",
       "      <td>5663.83</td>\n",
       "      <td>5631.16</td>\n",
       "      <td>5626.39</td>\n",
       "      <td>5569.47</td>\n",
       "      <td>5550.44</td>\n",
       "      <td>...</td>\n",
       "      <td>-581.91</td>\n",
       "      <td>-984.09</td>\n",
       "      <td>-1230.89</td>\n",
       "      <td>-1600.45</td>\n",
       "      <td>-1824.53</td>\n",
       "      <td>-2061.17</td>\n",
       "      <td>-2265.98</td>\n",
       "      <td>-2366.19</td>\n",
       "      <td>-2294.86</td>\n",
       "      <td>-2034.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>844.48</td>\n",
       "      <td>817.49</td>\n",
       "      <td>770.07</td>\n",
       "      <td>675.01</td>\n",
       "      <td>605.52</td>\n",
       "      <td>499.45</td>\n",
       "      <td>440.77</td>\n",
       "      <td>362.95</td>\n",
       "      <td>207.27</td>\n",
       "      <td>...</td>\n",
       "      <td>17.82</td>\n",
       "      <td>-51.66</td>\n",
       "      <td>-48.29</td>\n",
       "      <td>-59.99</td>\n",
       "      <td>-82.10</td>\n",
       "      <td>-174.54</td>\n",
       "      <td>-95.23</td>\n",
       "      <td>-162.68</td>\n",
       "      <td>-36.79</td>\n",
       "      <td>30.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>-826.00</td>\n",
       "      <td>-827.31</td>\n",
       "      <td>-846.12</td>\n",
       "      <td>-836.03</td>\n",
       "      <td>-745.50</td>\n",
       "      <td>-784.69</td>\n",
       "      <td>-791.22</td>\n",
       "      <td>-746.50</td>\n",
       "      <td>-709.53</td>\n",
       "      <td>...</td>\n",
       "      <td>122.34</td>\n",
       "      <td>93.03</td>\n",
       "      <td>93.03</td>\n",
       "      <td>68.81</td>\n",
       "      <td>9.81</td>\n",
       "      <td>20.75</td>\n",
       "      <td>20.25</td>\n",
       "      <td>-120.81</td>\n",
       "      <td>-257.56</td>\n",
       "      <td>-215.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-39.57</td>\n",
       "      <td>-15.88</td>\n",
       "      <td>-9.16</td>\n",
       "      <td>-6.37</td>\n",
       "      <td>-16.13</td>\n",
       "      <td>-24.05</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>-45.20</td>\n",
       "      <td>-5.04</td>\n",
       "      <td>...</td>\n",
       "      <td>-37.87</td>\n",
       "      <td>-61.85</td>\n",
       "      <td>-27.15</td>\n",
       "      <td>-21.18</td>\n",
       "      <td>-33.76</td>\n",
       "      <td>-85.34</td>\n",
       "      <td>-81.46</td>\n",
       "      <td>-61.98</td>\n",
       "      <td>-69.34</td>\n",
       "      <td>-17.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LABEL   FLUX.1   FLUX.2   FLUX.3   FLUX.4   FLUX.5   FLUX.6   FLUX.7  \\\n",
       "0      2   119.88   100.21    86.46    48.68    46.12    39.39    18.57   \n",
       "1      2  5736.59  5699.98  5717.16  5692.73  5663.83  5631.16  5626.39   \n",
       "2      2   844.48   817.49   770.07   675.01   605.52   499.45   440.77   \n",
       "3      2  -826.00  -827.31  -846.12  -836.03  -745.50  -784.69  -791.22   \n",
       "4      2   -39.57   -15.88    -9.16    -6.37   -16.13   -24.05    -0.90   \n",
       "\n",
       "    FLUX.8   FLUX.9    ...      FLUX.3188  FLUX.3189  FLUX.3190  FLUX.3191  \\\n",
       "0     6.98     6.63    ...          14.52      19.29      14.44      -1.62   \n",
       "1  5569.47  5550.44    ...        -581.91    -984.09   -1230.89   -1600.45   \n",
       "2   362.95   207.27    ...          17.82     -51.66     -48.29     -59.99   \n",
       "3  -746.50  -709.53    ...         122.34      93.03      93.03      68.81   \n",
       "4   -45.20    -5.04    ...         -37.87     -61.85     -27.15     -21.18   \n",
       "\n",
       "   FLUX.3192  FLUX.3193  FLUX.3194  FLUX.3195  FLUX.3196  FLUX.3197  \n",
       "0      13.33      45.50      31.93      35.78     269.43      57.72  \n",
       "1   -1824.53   -2061.17   -2265.98   -2366.19   -2294.86   -2034.72  \n",
       "2     -82.10    -174.54     -95.23    -162.68     -36.79      30.63  \n",
       "3       9.81      20.75      20.25    -120.81    -257.56    -215.41  \n",
       "4     -33.76     -85.34     -81.46     -61.98     -69.34     -17.84  \n",
       "\n",
       "[5 rows x 3198 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### combine the two datasets into one to regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfwhole = pd.concat([df,dftest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5657, 3198)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfwhole.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into training and test using train_test_split 80% train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into a training and test set.\n",
    "Xlr, Xtestlr, ylr, ytestlr = train_test_split(dfwhole.loc[:,'FLUX.1':].values, dfwhole['LABEL'].values, test_size =.8, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.665046398586\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C=1)\n",
    "\n",
    "# Fit the model on the trainng data.\n",
    "clf.fit(Xlr, ylr)\n",
    "# Print the accuracy from the testing data.\n",
    "print(accuracy_score(clf.predict(Xtestlr), ytestlr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Classification Report and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      0.66      0.80      4494\n",
      "          2       0.01      0.69      0.03        32\n",
      "\n",
      "avg / total       0.99      0.67      0.79      4526\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[2988   10]\n",
      " [1506   22]]\n",
      "\n",
      "Confusion Matrix:\n",
      " Predicted     1   2   All\n",
      "True                     \n",
      "1          2988  10  2998\n",
      "2          1506  22  1528\n",
      "All        4494  32  4526\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "#Print Confusion Matrix\n",
    "print ('\\nClassification Report:\\n', classification_report(ytestlr,clf.predict(Xtestlr)))\n",
    "#confusion_matrix_graph = confusion_matrix(clf.predict(Xtestlr),ytestlr)\n",
    "#print ('\\nConfusion Matrix:\\n',confusion_matrix_graph)\n",
    "print ('\\nConfusion Matrix:\\n', pd.crosstab( clf.predict(Xtestlr),ytestlr, rownames=['True'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 2, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(Xtestlr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics import roc_auc_score\n",
    "#y_true = np.array([0, 0, 1, 1])\n",
    "#y_scores = np.array([0.1, 0.4, 0.35, 0.8])\n",
    "#roc_auc_score(y_true, y_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_score(clf, x, y, score_func=accuracy_score):\n",
    "    result = 0\n",
    "    nfold = 5\n",
    "    for train, test in KFold(nfold).split(x): # split data into train/test groups, 5 times\n",
    "        clf.fit(x[train], y[train]) # fit\n",
    "        result += score_func(clf.predict(x[test]), y[test]) # evaluate score function on held-out data\n",
    "    return result / nfold # average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.654262991696\n"
     ]
    }
   ],
   "source": [
    "clf2 = LogisticRegression()\n",
    "score = cv_score(clf2, Xlr, ylr)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample through different C parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maxium: 0.6542746871466999\n",
      "Best value for C : 0.001\n"
     ]
    }
   ],
   "source": [
    "#the grid of parameters to search over\n",
    "Cs = [0.001, 0.1, 1, 10, 100]\n",
    "\n",
    "#For C parameters\n",
    "\n",
    "def Parameters_C(Cs):\n",
    "    \"\"\"\n",
    "    Input List of C values\n",
    "    Output Best C value as highest cv_score is tracked \n",
    "    \"\"\"\n",
    "    max_value = 0 \n",
    "    \n",
    "    for parameters in Cs:\n",
    "        logReg = LogisticRegression(C = parameters) #perform Log Reg with C\n",
    "        score = cv_score(logReg, Xlr, ylr) #get average score\n",
    "\n",
    "        if score > max_value:\n",
    "            max_value = score\n",
    "            top_C = parameters\n",
    "        \n",
    "    return max_value, top_C\n",
    "            \n",
    "max_value, top_C = Parameters_C(Cs)\n",
    "\n",
    "print('Maxium: {}'.format(max_value))\n",
    "print('Best value for C : {}'.format(top_C))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.645161290323\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C=top_C)\n",
    "# Fit the model on the trainng data.\n",
    "clf.fit(Xlr, ylr)\n",
    "# Print the accuracy from the testing data.\n",
    "print(accuracy_score(clf.predict(Xtestlr), ytestlr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xlr = df.loc[:,'FLUX.1':].values\n",
    "Xtestlr = dftest.loc[:,'FLUX.1':].values\n",
    "ylr = df['LABEL'].values\n",
    "ytestlr =dftest['LABEL'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.515789473684\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C=10)\n",
    "\n",
    "# Fit the model on the trainng data.\n",
    "clf.fit(Xlr, ylr)\n",
    "\n",
    "# Print the accuracy from the testing data.\n",
    "print(accuracy_score(clf.predict(Xtestlr), ytestlr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now with Normalized Scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and instatiate scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scale = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit and transform normalizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create separate array of Labals before transformation, remove labels from transformable dataset\n",
    "dfwhole_target = dfwhole['LABEL']\n",
    "dfwhole.drop('LABEL',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FLUX.1</th>\n",
       "      <th>FLUX.2</th>\n",
       "      <th>FLUX.3</th>\n",
       "      <th>FLUX.4</th>\n",
       "      <th>FLUX.5</th>\n",
       "      <th>FLUX.6</th>\n",
       "      <th>FLUX.7</th>\n",
       "      <th>FLUX.8</th>\n",
       "      <th>FLUX.9</th>\n",
       "      <th>FLUX.10</th>\n",
       "      <th>...</th>\n",
       "      <th>FLUX.3188</th>\n",
       "      <th>FLUX.3189</th>\n",
       "      <th>FLUX.3190</th>\n",
       "      <th>FLUX.3191</th>\n",
       "      <th>FLUX.3192</th>\n",
       "      <th>FLUX.3193</th>\n",
       "      <th>FLUX.3194</th>\n",
       "      <th>FLUX.3195</th>\n",
       "      <th>FLUX.3196</th>\n",
       "      <th>FLUX.3197</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93.85</td>\n",
       "      <td>83.81</td>\n",
       "      <td>20.10</td>\n",
       "      <td>-26.98</td>\n",
       "      <td>-39.56</td>\n",
       "      <td>-124.71</td>\n",
       "      <td>-135.18</td>\n",
       "      <td>-96.27</td>\n",
       "      <td>-79.89</td>\n",
       "      <td>-160.17</td>\n",
       "      <td>...</td>\n",
       "      <td>-78.07</td>\n",
       "      <td>-102.15</td>\n",
       "      <td>-102.15</td>\n",
       "      <td>25.13</td>\n",
       "      <td>48.57</td>\n",
       "      <td>92.54</td>\n",
       "      <td>39.32</td>\n",
       "      <td>61.42</td>\n",
       "      <td>5.08</td>\n",
       "      <td>-39.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-38.88</td>\n",
       "      <td>-33.83</td>\n",
       "      <td>-58.54</td>\n",
       "      <td>-40.09</td>\n",
       "      <td>-79.31</td>\n",
       "      <td>-72.81</td>\n",
       "      <td>-86.55</td>\n",
       "      <td>-85.33</td>\n",
       "      <td>-83.97</td>\n",
       "      <td>-73.38</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.28</td>\n",
       "      <td>-32.21</td>\n",
       "      <td>-32.21</td>\n",
       "      <td>-24.89</td>\n",
       "      <td>-4.86</td>\n",
       "      <td>0.76</td>\n",
       "      <td>-11.70</td>\n",
       "      <td>6.46</td>\n",
       "      <td>16.00</td>\n",
       "      <td>19.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>532.64</td>\n",
       "      <td>535.92</td>\n",
       "      <td>513.73</td>\n",
       "      <td>496.92</td>\n",
       "      <td>456.45</td>\n",
       "      <td>466.00</td>\n",
       "      <td>464.50</td>\n",
       "      <td>486.39</td>\n",
       "      <td>436.56</td>\n",
       "      <td>484.39</td>\n",
       "      <td>...</td>\n",
       "      <td>-71.69</td>\n",
       "      <td>13.31</td>\n",
       "      <td>13.31</td>\n",
       "      <td>-29.89</td>\n",
       "      <td>-20.88</td>\n",
       "      <td>5.06</td>\n",
       "      <td>-11.80</td>\n",
       "      <td>-28.91</td>\n",
       "      <td>-70.02</td>\n",
       "      <td>-96.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>326.52</td>\n",
       "      <td>347.39</td>\n",
       "      <td>302.35</td>\n",
       "      <td>298.13</td>\n",
       "      <td>317.74</td>\n",
       "      <td>312.70</td>\n",
       "      <td>322.33</td>\n",
       "      <td>311.31</td>\n",
       "      <td>312.42</td>\n",
       "      <td>323.33</td>\n",
       "      <td>...</td>\n",
       "      <td>5.71</td>\n",
       "      <td>-3.73</td>\n",
       "      <td>-3.73</td>\n",
       "      <td>30.05</td>\n",
       "      <td>20.03</td>\n",
       "      <td>-12.67</td>\n",
       "      <td>-8.77</td>\n",
       "      <td>-17.31</td>\n",
       "      <td>-17.35</td>\n",
       "      <td>13.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1107.21</td>\n",
       "      <td>-1112.59</td>\n",
       "      <td>-1118.95</td>\n",
       "      <td>-1095.10</td>\n",
       "      <td>-1057.55</td>\n",
       "      <td>-1034.48</td>\n",
       "      <td>-998.34</td>\n",
       "      <td>-1022.71</td>\n",
       "      <td>-989.57</td>\n",
       "      <td>-970.88</td>\n",
       "      <td>...</td>\n",
       "      <td>-594.37</td>\n",
       "      <td>-401.66</td>\n",
       "      <td>-401.66</td>\n",
       "      <td>-357.24</td>\n",
       "      <td>-443.76</td>\n",
       "      <td>-438.54</td>\n",
       "      <td>-399.71</td>\n",
       "      <td>-384.65</td>\n",
       "      <td>-411.79</td>\n",
       "      <td>-510.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3197 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    FLUX.1   FLUX.2   FLUX.3   FLUX.4   FLUX.5   FLUX.6  FLUX.7   FLUX.8  \\\n",
       "0    93.85    83.81    20.10   -26.98   -39.56  -124.71 -135.18   -96.27   \n",
       "1   -38.88   -33.83   -58.54   -40.09   -79.31   -72.81  -86.55   -85.33   \n",
       "2   532.64   535.92   513.73   496.92   456.45   466.00  464.50   486.39   \n",
       "3   326.52   347.39   302.35   298.13   317.74   312.70  322.33   311.31   \n",
       "4 -1107.21 -1112.59 -1118.95 -1095.10 -1057.55 -1034.48 -998.34 -1022.71   \n",
       "\n",
       "   FLUX.9  FLUX.10    ...      FLUX.3188  FLUX.3189  FLUX.3190  FLUX.3191  \\\n",
       "0  -79.89  -160.17    ...         -78.07    -102.15    -102.15      25.13   \n",
       "1  -83.97   -73.38    ...          -3.28     -32.21     -32.21     -24.89   \n",
       "2  436.56   484.39    ...         -71.69      13.31      13.31     -29.89   \n",
       "3  312.42   323.33    ...           5.71      -3.73      -3.73      30.05   \n",
       "4 -989.57  -970.88    ...        -594.37    -401.66    -401.66    -357.24   \n",
       "\n",
       "   FLUX.3192  FLUX.3193  FLUX.3194  FLUX.3195  FLUX.3196  FLUX.3197  \n",
       "0      48.57      92.54      39.32      61.42       5.08     -39.54  \n",
       "1      -4.86       0.76     -11.70       6.46      16.00      19.93  \n",
       "2     -20.88       5.06     -11.80     -28.91     -70.02     -96.67  \n",
       "3      20.03     -12.67      -8.77     -17.31     -17.35      13.98  \n",
       "4    -443.76    -438.54    -399.71    -384.65    -411.79    -510.54  \n",
       "\n",
       "[5 rows x 3197 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfwhole.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = dfwhole.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Whole Dataset \n",
    "dfwhole_scale = scale.fit_transform(dfwhole.as_matrix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert back to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Whole Dataset \n",
    "dfwhole_scale = pd.DataFrame(dfwhole_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfwhole_scale.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfwhole_scale.columns = column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FLUX.1</th>\n",
       "      <th>FLUX.2</th>\n",
       "      <th>FLUX.3</th>\n",
       "      <th>FLUX.4</th>\n",
       "      <th>FLUX.5</th>\n",
       "      <th>FLUX.6</th>\n",
       "      <th>FLUX.7</th>\n",
       "      <th>FLUX.8</th>\n",
       "      <th>FLUX.9</th>\n",
       "      <th>FLUX.10</th>\n",
       "      <th>...</th>\n",
       "      <th>FLUX.3188</th>\n",
       "      <th>FLUX.3189</th>\n",
       "      <th>FLUX.3190</th>\n",
       "      <th>FLUX.3191</th>\n",
       "      <th>FLUX.3192</th>\n",
       "      <th>FLUX.3193</th>\n",
       "      <th>FLUX.3194</th>\n",
       "      <th>FLUX.3195</th>\n",
       "      <th>FLUX.3196</th>\n",
       "      <th>FLUX.3197</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.004236</td>\n",
       "      <td>-0.005043</td>\n",
       "      <td>-0.007841</td>\n",
       "      <td>-0.011275</td>\n",
       "      <td>-0.010495</td>\n",
       "      <td>-0.014239</td>\n",
       "      <td>-0.012587</td>\n",
       "      <td>-0.012311</td>\n",
       "      <td>-0.011753</td>\n",
       "      <td>-0.018687</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014546</td>\n",
       "      <td>-0.017118</td>\n",
       "      <td>-0.017280</td>\n",
       "      <td>-0.014300</td>\n",
       "      <td>-0.012122</td>\n",
       "      <td>-0.010372</td>\n",
       "      <td>0.026682</td>\n",
       "      <td>0.031563</td>\n",
       "      <td>0.024062</td>\n",
       "      <td>0.015458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.010624</td>\n",
       "      <td>-0.010631</td>\n",
       "      <td>-0.011558</td>\n",
       "      <td>-0.011886</td>\n",
       "      <td>-0.012282</td>\n",
       "      <td>-0.012002</td>\n",
       "      <td>-0.010493</td>\n",
       "      <td>-0.011816</td>\n",
       "      <td>-0.011954</td>\n",
       "      <td>-0.014080</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011809</td>\n",
       "      <td>-0.015050</td>\n",
       "      <td>-0.015588</td>\n",
       "      <td>-0.015357</td>\n",
       "      <td>-0.013227</td>\n",
       "      <td>-0.012181</td>\n",
       "      <td>0.023712</td>\n",
       "      <td>0.028344</td>\n",
       "      <td>0.024757</td>\n",
       "      <td>0.019690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.016880</td>\n",
       "      <td>0.016432</td>\n",
       "      <td>0.015493</td>\n",
       "      <td>0.013141</td>\n",
       "      <td>0.011802</td>\n",
       "      <td>0.011220</td>\n",
       "      <td>0.013229</td>\n",
       "      <td>0.014076</td>\n",
       "      <td>0.013661</td>\n",
       "      <td>0.015525</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014312</td>\n",
       "      <td>-0.013704</td>\n",
       "      <td>-0.014488</td>\n",
       "      <td>-0.015463</td>\n",
       "      <td>-0.013559</td>\n",
       "      <td>-0.012096</td>\n",
       "      <td>0.023706</td>\n",
       "      <td>0.026272</td>\n",
       "      <td>0.019286</td>\n",
       "      <td>0.011392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.006961</td>\n",
       "      <td>0.007477</td>\n",
       "      <td>0.005501</td>\n",
       "      <td>0.003877</td>\n",
       "      <td>0.005566</td>\n",
       "      <td>0.004613</td>\n",
       "      <td>0.007109</td>\n",
       "      <td>0.006147</td>\n",
       "      <td>0.007552</td>\n",
       "      <td>0.006976</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011480</td>\n",
       "      <td>-0.014208</td>\n",
       "      <td>-0.014900</td>\n",
       "      <td>-0.014196</td>\n",
       "      <td>-0.012712</td>\n",
       "      <td>-0.012446</td>\n",
       "      <td>0.023882</td>\n",
       "      <td>0.026952</td>\n",
       "      <td>0.022636</td>\n",
       "      <td>0.019267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.062035</td>\n",
       "      <td>-0.061872</td>\n",
       "      <td>-0.061682</td>\n",
       "      <td>-0.061053</td>\n",
       "      <td>-0.056257</td>\n",
       "      <td>-0.053449</td>\n",
       "      <td>-0.049746</td>\n",
       "      <td>-0.054268</td>\n",
       "      <td>-0.056517</td>\n",
       "      <td>-0.061718</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033436</td>\n",
       "      <td>-0.025975</td>\n",
       "      <td>-0.024522</td>\n",
       "      <td>-0.022379</td>\n",
       "      <td>-0.022308</td>\n",
       "      <td>-0.020841</td>\n",
       "      <td>0.001127</td>\n",
       "      <td>0.005435</td>\n",
       "      <td>-0.002453</td>\n",
       "      <td>-0.018060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3197 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FLUX.1    FLUX.2    FLUX.3    FLUX.4    FLUX.5    FLUX.6    FLUX.7  \\\n",
       "0 -0.004236 -0.005043 -0.007841 -0.011275 -0.010495 -0.014239 -0.012587   \n",
       "1 -0.010624 -0.010631 -0.011558 -0.011886 -0.012282 -0.012002 -0.010493   \n",
       "2  0.016880  0.016432  0.015493  0.013141  0.011802  0.011220  0.013229   \n",
       "3  0.006961  0.007477  0.005501  0.003877  0.005566  0.004613  0.007109   \n",
       "4 -0.062035 -0.061872 -0.061682 -0.061053 -0.056257 -0.053449 -0.049746   \n",
       "\n",
       "     FLUX.8    FLUX.9   FLUX.10    ...      FLUX.3188  FLUX.3189  FLUX.3190  \\\n",
       "0 -0.012311 -0.011753 -0.018687    ...      -0.014546  -0.017118  -0.017280   \n",
       "1 -0.011816 -0.011954 -0.014080    ...      -0.011809  -0.015050  -0.015588   \n",
       "2  0.014076  0.013661  0.015525    ...      -0.014312  -0.013704  -0.014488   \n",
       "3  0.006147  0.007552  0.006976    ...      -0.011480  -0.014208  -0.014900   \n",
       "4 -0.054268 -0.056517 -0.061718    ...      -0.033436  -0.025975  -0.024522   \n",
       "\n",
       "   FLUX.3191  FLUX.3192  FLUX.3193  FLUX.3194  FLUX.3195  FLUX.3196  FLUX.3197  \n",
       "0  -0.014300  -0.012122  -0.010372   0.026682   0.031563   0.024062   0.015458  \n",
       "1  -0.015357  -0.013227  -0.012181   0.023712   0.028344   0.024757   0.019690  \n",
       "2  -0.015463  -0.013559  -0.012096   0.023706   0.026272   0.019286   0.011392  \n",
       "3  -0.014196  -0.012712  -0.012446   0.023882   0.026952   0.022636   0.019267  \n",
       "4  -0.022379  -0.022308  -0.020841   0.001127   0.005435  -0.002453  -0.018060  \n",
       "\n",
       "[5 rows x 3197 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfwhole_scale.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LABEL\n",
       "0      2\n",
       "1      2\n",
       "2      2\n",
       "3      2\n",
       "4      2"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfwhole_target = pd.DataFrame(dfwhole_target)\n",
    "dfwhole_target.reset_index(inplace=True, drop=True)\n",
    "dfwhole_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfwhole_target.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5657, 3197)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfwhole_scale.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5657, 3198)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_col_merged =pd.concat([dfwhole_target, dfwhole_scale], axis=1)\n",
    "df_col_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>FLUX.1</th>\n",
       "      <th>FLUX.2</th>\n",
       "      <th>FLUX.3</th>\n",
       "      <th>FLUX.4</th>\n",
       "      <th>FLUX.5</th>\n",
       "      <th>FLUX.6</th>\n",
       "      <th>FLUX.7</th>\n",
       "      <th>FLUX.8</th>\n",
       "      <th>FLUX.9</th>\n",
       "      <th>...</th>\n",
       "      <th>FLUX.3188</th>\n",
       "      <th>FLUX.3189</th>\n",
       "      <th>FLUX.3190</th>\n",
       "      <th>FLUX.3191</th>\n",
       "      <th>FLUX.3192</th>\n",
       "      <th>FLUX.3193</th>\n",
       "      <th>FLUX.3194</th>\n",
       "      <th>FLUX.3195</th>\n",
       "      <th>FLUX.3196</th>\n",
       "      <th>FLUX.3197</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.004236</td>\n",
       "      <td>-0.005043</td>\n",
       "      <td>-0.007841</td>\n",
       "      <td>-0.011275</td>\n",
       "      <td>-0.010495</td>\n",
       "      <td>-0.014239</td>\n",
       "      <td>-0.012587</td>\n",
       "      <td>-0.012311</td>\n",
       "      <td>-0.011753</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014546</td>\n",
       "      <td>-0.017118</td>\n",
       "      <td>-0.017280</td>\n",
       "      <td>-0.014300</td>\n",
       "      <td>-0.012122</td>\n",
       "      <td>-0.010372</td>\n",
       "      <td>0.026682</td>\n",
       "      <td>0.031563</td>\n",
       "      <td>0.024062</td>\n",
       "      <td>0.015458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.010624</td>\n",
       "      <td>-0.010631</td>\n",
       "      <td>-0.011558</td>\n",
       "      <td>-0.011886</td>\n",
       "      <td>-0.012282</td>\n",
       "      <td>-0.012002</td>\n",
       "      <td>-0.010493</td>\n",
       "      <td>-0.011816</td>\n",
       "      <td>-0.011954</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011809</td>\n",
       "      <td>-0.015050</td>\n",
       "      <td>-0.015588</td>\n",
       "      <td>-0.015357</td>\n",
       "      <td>-0.013227</td>\n",
       "      <td>-0.012181</td>\n",
       "      <td>0.023712</td>\n",
       "      <td>0.028344</td>\n",
       "      <td>0.024757</td>\n",
       "      <td>0.019690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.016880</td>\n",
       "      <td>0.016432</td>\n",
       "      <td>0.015493</td>\n",
       "      <td>0.013141</td>\n",
       "      <td>0.011802</td>\n",
       "      <td>0.011220</td>\n",
       "      <td>0.013229</td>\n",
       "      <td>0.014076</td>\n",
       "      <td>0.013661</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014312</td>\n",
       "      <td>-0.013704</td>\n",
       "      <td>-0.014488</td>\n",
       "      <td>-0.015463</td>\n",
       "      <td>-0.013559</td>\n",
       "      <td>-0.012096</td>\n",
       "      <td>0.023706</td>\n",
       "      <td>0.026272</td>\n",
       "      <td>0.019286</td>\n",
       "      <td>0.011392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.006961</td>\n",
       "      <td>0.007477</td>\n",
       "      <td>0.005501</td>\n",
       "      <td>0.003877</td>\n",
       "      <td>0.005566</td>\n",
       "      <td>0.004613</td>\n",
       "      <td>0.007109</td>\n",
       "      <td>0.006147</td>\n",
       "      <td>0.007552</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011480</td>\n",
       "      <td>-0.014208</td>\n",
       "      <td>-0.014900</td>\n",
       "      <td>-0.014196</td>\n",
       "      <td>-0.012712</td>\n",
       "      <td>-0.012446</td>\n",
       "      <td>0.023882</td>\n",
       "      <td>0.026952</td>\n",
       "      <td>0.022636</td>\n",
       "      <td>0.019267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.062035</td>\n",
       "      <td>-0.061872</td>\n",
       "      <td>-0.061682</td>\n",
       "      <td>-0.061053</td>\n",
       "      <td>-0.056257</td>\n",
       "      <td>-0.053449</td>\n",
       "      <td>-0.049746</td>\n",
       "      <td>-0.054268</td>\n",
       "      <td>-0.056517</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033436</td>\n",
       "      <td>-0.025975</td>\n",
       "      <td>-0.024522</td>\n",
       "      <td>-0.022379</td>\n",
       "      <td>-0.022308</td>\n",
       "      <td>-0.020841</td>\n",
       "      <td>0.001127</td>\n",
       "      <td>0.005435</td>\n",
       "      <td>-0.002453</td>\n",
       "      <td>-0.018060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LABEL    FLUX.1    FLUX.2    FLUX.3    FLUX.4    FLUX.5    FLUX.6  \\\n",
       "0      2 -0.004236 -0.005043 -0.007841 -0.011275 -0.010495 -0.014239   \n",
       "1      2 -0.010624 -0.010631 -0.011558 -0.011886 -0.012282 -0.012002   \n",
       "2      2  0.016880  0.016432  0.015493  0.013141  0.011802  0.011220   \n",
       "3      2  0.006961  0.007477  0.005501  0.003877  0.005566  0.004613   \n",
       "4      2 -0.062035 -0.061872 -0.061682 -0.061053 -0.056257 -0.053449   \n",
       "\n",
       "     FLUX.7    FLUX.8    FLUX.9    ...      FLUX.3188  FLUX.3189  FLUX.3190  \\\n",
       "0 -0.012587 -0.012311 -0.011753    ...      -0.014546  -0.017118  -0.017280   \n",
       "1 -0.010493 -0.011816 -0.011954    ...      -0.011809  -0.015050  -0.015588   \n",
       "2  0.013229  0.014076  0.013661    ...      -0.014312  -0.013704  -0.014488   \n",
       "3  0.007109  0.006147  0.007552    ...      -0.011480  -0.014208  -0.014900   \n",
       "4 -0.049746 -0.054268 -0.056517    ...      -0.033436  -0.025975  -0.024522   \n",
       "\n",
       "   FLUX.3191  FLUX.3192  FLUX.3193  FLUX.3194  FLUX.3195  FLUX.3196  FLUX.3197  \n",
       "0  -0.014300  -0.012122  -0.010372   0.026682   0.031563   0.024062   0.015458  \n",
       "1  -0.015357  -0.013227  -0.012181   0.023712   0.028344   0.024757   0.019690  \n",
       "2  -0.015463  -0.013559  -0.012096   0.023706   0.026272   0.019286   0.011392  \n",
       "3  -0.014196  -0.012712  -0.012446   0.023882   0.026952   0.022636   0.019267  \n",
       "4  -0.022379  -0.022308  -0.020841   0.001127   0.005435  -0.002453  -0.018060  \n",
       "\n",
       "[5 rows x 3198 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_col_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into a training and test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the logistic model : Test size 80% and random state 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into a training and test set.\n",
    "Xlr, Xtestlr, ylr, ytestlr = train_test_split(df_col_merged.loc[:,'FLUX.1':].values, df_col_merged['LABEL'].values, test_size =.8, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.978789217852\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C=10)\n",
    "\n",
    "# Fit the model on the trainng data.\n",
    "clf.fit(Xlr, ylr)\n",
    "\n",
    "# Print the accuracy from the testing data.\n",
    "print(accuracy_score(clf.predict(Xtestlr), ytestlr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the logistic model : Test size 70% and random state 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into a training and test set.\n",
    "Xlr, Xtestlr, ylr, ytestlr = train_test_split(df_col_merged.loc[:,'FLUX.1':].values, df_col_merged['LABEL'].values, test_size =.7, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.986363636364\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C=1)\n",
    "\n",
    "# Fit the model on the trainng data.\n",
    "clf.fit(Xlr, ylr)\n",
    "\n",
    "# Print the accuracy from the testing data.\n",
    "print(accuracy_score(clf.predict(Xtestlr), ytestlr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now for the Competition Breakdown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df & dftest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore Star Light Intensity with & without exoPlanet\n",
    "# remove the label data\n",
    "\n",
    "#create separate array of Labels before transformation, remove labels from transformable dataset\n",
    "df_target = df['LABEL']\n",
    "df.drop('LABEL',axis=1,inplace=True)\n",
    "\n",
    "dftest_target = dftest['LABEL']\n",
    "dftest.drop('LABEL',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Competition Split: Fit Transform\n",
    "dftrain_scale = scale.fit_transform(df.as_matrix())\n",
    "dftest_scale = scale.fit_transform(dftest.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Competition Split: Revert to Dataset\n",
    "dftrain_scale = pd.DataFrame(dftrain_scale)\n",
    "dftest_scale = pd.DataFrame(dftest_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.984210526316\n"
     ]
    }
   ],
   "source": [
    "clf_c = LogisticRegression(C=1)\n",
    "\n",
    "# Fit the model on the trainng data.\n",
    "clf_c.fit(dftrain_scale, df_target)\n",
    "\n",
    "# Print the accuracy from the testing data.\n",
    "print(accuracy_score(clf.predict(dftest_scale), dftest_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Working with a group of classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign the classifiers \n",
    "svc = SVC(kernel='sigmoid', gamma=1.0)\n",
    "knc = KNeighborsClassifier(n_neighbors=5)\n",
    "mnb = MultinomialNB(alpha=0.2)\n",
    "dtc = DecisionTreeClassifier(min_samples_split=7, random_state=111)\n",
    "lrc = LogisticRegression(solver='liblinear', penalty='l1')\n",
    "rfc = RandomForestClassifier(n_estimators=31, random_state=111)\n",
    "abc = AdaBoostClassifier(n_estimators=62, random_state=111)\n",
    "bc = BaggingClassifier(n_estimators=9, random_state=111)\n",
    "etc = ExtraTreesClassifier(n_estimators=9, random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = {'SVC' : svc,'KN' : knc, 'DT': dtc, 'LR': lrc, 'RF': rfc, 'AdaBoost': abc, 'BgC': bc, 'ETC': etc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(clf, feature_train, labels_train):\n",
    "    \"\"\"create the classfier feeder to fit the features and labels\"\"\"\n",
    "    clf.fit(feature_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_labels(clf, features):\n",
    "    \"\"\"predicted values from the features matrix\"\"\"\n",
    "    return (clf.predict(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC\n",
      "\n",
      "Classification Report:  SVC \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.99      1.00      1.00      3933\n",
      "          2       0.00      0.00      0.00        27\n",
      "\n",
      "avg / total       0.99      0.99      0.99      3960\n",
      "\n",
      "\n",
      "Confusion Matrix:  SVC \n",
      " Predicted     1   2   All\n",
      "True                     \n",
      "1          3924  27  3951\n",
      "2             9   0     9\n",
      "All        3933  27  3960\n",
      "KN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:  KN \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.99      1.00      1.00      3933\n",
      "          2       0.00      0.00      0.00        27\n",
      "\n",
      "avg / total       0.99      0.99      0.99      3960\n",
      "\n",
      "\n",
      "Confusion Matrix:  KN \n",
      " Predicted     1   2   All\n",
      "True                     \n",
      "1          3933  27  3960\n",
      "All        3933  27  3960\n",
      "DT\n",
      "\n",
      "Classification Report:  DT \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.99      0.98      0.99      3933\n",
      "          2       0.02      0.07      0.04        27\n",
      "\n",
      "avg / total       0.99      0.97      0.98      3960\n",
      "\n",
      "\n",
      "Confusion Matrix:  DT \n",
      " Predicted     1   2   All\n",
      "True                     \n",
      "1          3853  25  3878\n",
      "2            80   2    82\n",
      "All        3933  27  3960\n",
      "LR\n",
      "\n",
      "Classification Report:  LR \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.99      1.00      1.00      3933\n",
      "          2       0.00      0.00      0.00        27\n",
      "\n",
      "avg / total       0.99      0.99      0.99      3960\n",
      "\n",
      "\n",
      "Confusion Matrix:  LR \n",
      " Predicted     1   2   All\n",
      "True                     \n",
      "1          3933  27  3960\n",
      "All        3933  27  3960\n",
      "RF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:  RF \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.99      1.00      1.00      3933\n",
      "          2       0.00      0.00      0.00        27\n",
      "\n",
      "avg / total       0.99      0.99      0.99      3960\n",
      "\n",
      "\n",
      "Confusion Matrix:  RF \n",
      " Predicted     1   2   All\n",
      "True                     \n",
      "1          3933  27  3960\n",
      "All        3933  27  3960\n",
      "AdaBoost\n",
      "\n",
      "Classification Report:  AdaBoost \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.99      1.00      0.99      3933\n",
      "          2       0.00      0.00      0.00        27\n",
      "\n",
      "avg / total       0.99      0.99      0.99      3960\n",
      "\n",
      "\n",
      "Confusion Matrix:  AdaBoost \n",
      " Predicted     1   2   All\n",
      "True                     \n",
      "1          3920  27  3947\n",
      "2            13   0    13\n",
      "All        3933  27  3960\n",
      "BgC\n",
      "\n",
      "Classification Report:  BgC \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.99      1.00      1.00      3933\n",
      "          2       0.00      0.00      0.00        27\n",
      "\n",
      "avg / total       0.99      0.99      0.99      3960\n",
      "\n",
      "\n",
      "Confusion Matrix:  BgC \n",
      " Predicted     1   2   All\n",
      "True                     \n",
      "1          3925  27  3952\n",
      "2             8   0     8\n",
      "All        3933  27  3960\n",
      "ETC\n",
      "\n",
      "Classification Report:  ETC \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.99      1.00      1.00      3933\n",
      "          2       0.00      0.00      0.00        27\n",
      "\n",
      "avg / total       0.99      0.99      0.99      3960\n",
      "\n",
      "\n",
      "Confusion Matrix:  ETC \n",
      " Predicted     1   2   All\n",
      "True                     \n",
      "1          3932  27  3959\n",
      "2             1   0     1\n",
      "All        3933  27  3960\n"
     ]
    }
   ],
   "source": [
    "features_train = Xlr\n",
    "labels_train = ylr\n",
    "features_test = Xtestlr\n",
    "labels_test = ytestlr\n",
    "\n",
    "pred_scores = []\n",
    "for k,v in clfs.items():\n",
    "    #print(k)\n",
    "    train_classifier(v, features_train, labels_train)\n",
    "    pred = predict_labels(v,features_test)\n",
    "    pred_scores.append((k, [accuracy_score(labels_test,pred)]))\n",
    "    print ('\\nClassification Report: ', k,'\\n', classification_report(ytestlr,v.predict(Xtestlr)))\n",
    "    print ('\\nConfusion Matrix: ',k,'\\n', pd.crosstab( v.predict(Xtestlr),ytestlr, rownames=['True'], colnames=['Predicted'], margins=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.986522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KN</th>\n",
       "      <td>0.992930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>0.976580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.992930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.992930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.992709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BgC</th>\n",
       "      <td>0.988069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ETC</th>\n",
       "      <td>0.992488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Score\n",
       "SVC       0.986522\n",
       "KN        0.992930\n",
       "DT        0.976580\n",
       "LR        0.992930\n",
       "RF        0.992930\n",
       "AdaBoost  0.992709\n",
       "BgC       0.988069\n",
       "ETC       0.992488"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = pd.DataFrame.from_items(pred_scores,orient='index', columns=['Score'])\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
